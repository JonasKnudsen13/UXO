{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d5b657",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# BSC THESIS - MACHINE LEARNING FOR UNEXPLODED ORDNANCE (UXO)\n",
    "# THIS NOTEBOOK IS DEVELOPED BY JONAS KNUDSEN WITH CODE FROM \n",
    "# https://towardsdatascience.com/understanding-and-implementing-faster-r-cnn-a-step-by-step-guide-11acfff216b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf858c1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%% MODULES %%%%%%%%%% #\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import ops\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchmetrics.classification import BinaryStatScores\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c07360a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%% GLOBAL  %%%%%%%%%% #\n",
    "# TRANSFER MODEL TO GPU IF AVAILABLE\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\") # 'cpu' works\n",
    "# Not strictly necessary but can potentially speed up the network and improve memory footprint\n",
    "torch.backends.cudnn.benchmark = True\n",
    "#print(f\"Using device: {device}\")    \n",
    "\n",
    "dataset_start_number = 1000001\n",
    "dsn = dataset_start_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d869890f",
   "metadata": {
    "code_folding": [
     0,
     3,
     100
    ]
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%% DATASET %%%%%%%%%% #\n",
    "\n",
    "### JONAS ###\n",
    "class UXO_dataset(Dataset):\n",
    "    # takes a list of file ids and a directory root\n",
    "    def __init__(self, file_list, file_root):\n",
    "        self.file_list = file_list\n",
    "        self.file_root = file_root\n",
    "        \n",
    "        self.folder_name = self.file_root.split('/')[-1]\n",
    "        \n",
    "        self.all_images, self.all_BBs = self.get_data()\n",
    "    \n",
    "    def __len__(self):\n",
    "        #return(len(self.file_list))\n",
    "        return self.all_images.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.all_images[index].float()\n",
    "        BB = self.all_BBs[index]\n",
    "        \n",
    "        return image, BB\n",
    "    \n",
    "    \n",
    "    def get_data(self):\n",
    "        start_time_global = time.perf_counter()\n",
    "        all_images = []\n",
    "        all_BBs = []\n",
    "        \n",
    "        if self.folder_name == 'augmentedData' or self.folder_name == 'augmentedData_hard':\n",
    "            split = 10000\n",
    "        \n",
    "        if self.folder_name == 'augmentedData_big' or self.folder_name == 'augmentedData_hard_big':\n",
    "            split = 25000\n",
    "        \n",
    "        count = 1\n",
    "        \n",
    "        print_count_number = 5000\n",
    "        \n",
    "        for i in self.file_list:\n",
    "            \n",
    "\n",
    "            if i >= dsn+0*split and i < dsn + 1*split:\n",
    "                survey_number = '1'\n",
    "            if i >= dsn+1*split and i < dsn + 2*split:\n",
    "                survey_number = '2'\n",
    "            if i >= dsn+2*split and i < dsn + 3*split:\n",
    "                survey_number = '3'\n",
    "            if i >= dsn+3*split and i < dsn + 4*split:\n",
    "                survey_number = '4'\n",
    "\n",
    "            image_dir = f'{self.file_root}/survey_{survey_number}/images/image_'+str(i)+'.npy'\n",
    "            BB_dir = f'{self.file_root}/survey_{survey_number}/labels/BB_'+str(i)+'.npy'\n",
    "\n",
    "            \n",
    "            if count % print_count_number == 0:\n",
    "                if count == print_count_number:\n",
    "                    start_time = start_time_global\n",
    "                \n",
    "                end_time = time.perf_counter()\n",
    "                # Calculate the elapsed time\n",
    "                elapsed_time = np.round(end_time - start_time,1)\n",
    "\n",
    "                # Print the elapsed time\n",
    "                print('Loaded '+ str(count) + ' images. ' + f'Elapsed time {elapsed_time} seconds' )\n",
    "                start_time = time.perf_counter()\n",
    "            \n",
    "            image = np.load(image_dir)\n",
    "            BB = np.load(BB_dir)\n",
    "            \n",
    "            # change from [row,col,height,width]\n",
    "            # to the form [x  ,y  ,width,height]\n",
    "            if BB.shape == (0,):\n",
    "                BB = np.array([[-1,-1,-1,-1]],dtype=BB.dtype)\n",
    "            \n",
    "            BB = BB[:,[1,0,3,2]]\n",
    "            \n",
    "            \n",
    "            image_tensor = torch.from_numpy(image).permute(2,0,1)\n",
    "            #image_tensor = image_tensor.float()\n",
    "            \n",
    "            BB_tensor = torch.from_numpy(BB) \n",
    "            BB_tensor = ops.box_convert(BB_tensor,'cxcywh','xyxy')\n",
    "            \n",
    "            all_images.append(image_tensor)\n",
    "            all_BBs.append(BB_tensor)\n",
    "            count+=1\n",
    "        \n",
    "        all_images_stacked = torch.stack(all_images, dim=0)\n",
    "        all_BBs_padded = pad_sequence(all_BBs,batch_first=True,padding_value=-1)\n",
    "        \n",
    "        end_time_global = time.perf_counter()\n",
    "\n",
    "        # Calculate the elapsed time\n",
    "        elapsed_time_global = np.round(end_time_global - start_time_global,1)\n",
    "\n",
    "        # Print the elapsed time\n",
    "        print('Loaded all '+ str(count-1) + ' images. ' + 'Total time: ' + str(elapsed_time_global)+ ' seconds')\n",
    "        return all_images_stacked, all_BBs_padded\n",
    "    \n",
    "class UXO_dataset_old(Dataset):\n",
    "    # takes a list of file ids and a directory root\n",
    "    def __init__(self, file_list, file_root):\n",
    "        self.file_list = file_list\n",
    "        self.file_root = file_root\n",
    "        \n",
    "        self.all_images, self.all_BBs = self.get_data()\n",
    "    \n",
    "    def __len__(self):\n",
    "        #return(len(self.file_list))\n",
    "        return self.all_images.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.all_images[index].float()\n",
    "        BB = self.all_BBs[index]\n",
    "        \n",
    "        return image, BB\n",
    "    \n",
    "    \n",
    "    def get_data(self):\n",
    "        \n",
    "        all_images = []\n",
    "        all_BBs = []\n",
    "        \n",
    "        for i in self.file_list:\n",
    "            image_dir = f'{self.file_root}/image_'+str(i)+'.npy'\n",
    "            BB_dir = f'{self.file_root}/BB_'+str(i)+'.npy'\n",
    "            \n",
    "            image = np.load(image_dir)\n",
    "            BB = np.load(BB_dir)\n",
    "            print(i)\n",
    "            # change from [row,col,height,width]\n",
    "            # to the form [x  ,y  ,width,height]\n",
    "            if BB.shape == (0,):\n",
    "                BB = np.array([[-1,-1,-1,-1]],dtype=BB.dtype)\n",
    "            \n",
    "            BB = BB[:,[1,0,3,2]]\n",
    "        \n",
    "            \n",
    "            image_tensor = torch.from_numpy(image).permute(2,0,1)\n",
    "            #image_tensor = image_tensor.float()\n",
    "            \n",
    "            BB_tensor = torch.from_numpy(BB) \n",
    "            BB_tensor = ops.box_convert(BB_tensor,'cxcywh','xyxy')\n",
    "            \n",
    "            all_images.append(image_tensor)\n",
    "            all_BBs.append(BB_tensor)\n",
    "        \n",
    "        all_images_stacked = torch.stack(all_images, dim=0)\n",
    "        all_BBs_padded = pad_sequence(all_BBs,batch_first=True,padding_value=-1)\n",
    "        \n",
    "        return all_images_stacked, all_BBs_padded\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ee5496",
   "metadata": {
    "code_folding": [
     0,
     2,
     18,
     32,
     90,
     154,
     201,
     240,
     241,
     348,
     349,
     389,
     390,
     434,
     445,
     451,
     464
    ]
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%%  MODEL  %%%%%%%%%% #\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        model = model.float() # EDIT: Jonas added this\n",
    "        \n",
    "        req_layers = list(model.children())[:5] # EDIT: Jonas changed 8 to 5\n",
    "        self.backbone = nn.Sequential(*req_layers)\n",
    "        for param in self.backbone.named_parameters():\n",
    "            param[1].requires_grad = True\n",
    "        \n",
    "    def forward(self, img_data):\n",
    "        return self.backbone(img_data)\n",
    "    \n",
    "\n",
    "### JONAS ###    \n",
    "class FeatureExtractor_random(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.resnet50()\n",
    "        model = model.float()# EDIT: Jonas added this\n",
    "        \n",
    "        req_layers = list(model.children())[:5] # EDIT: Jonas changed 8 to 5\n",
    "        self.backbone = nn.Sequential(*req_layers)\n",
    "        for param in self.backbone.named_parameters():\n",
    "            param[1].requires_grad = True\n",
    "        \n",
    "    def forward(self, img_data):\n",
    "        return self.backbone(img_data)\n",
    "\n",
    "class FeatureExtractor_hyper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input is (b,3,256,256)\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(11,11), stride=2, padding=5)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64), \n",
    "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2)),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,5), padding=2)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1)\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Conv2d(128, 128, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img_data):\n",
    "        \n",
    "        img_data = img_data.float()        \n",
    "        out1 = self.block1(img_data)        \n",
    "        out2 = self.block2(out1)        \n",
    "        out3 = self.block3(out2)        \n",
    "        out4 = self.block4(out3)        \n",
    "        out5 = self.block5(out4)\n",
    "                \n",
    "        # Assembling the Hyper Feature Map\n",
    "        \n",
    "        # Reduce the row and col by a factor of 1/2\n",
    "        hyper_out1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        hyper_out1 = hyper_out1(out1)\n",
    "        \n",
    "        hyper_out3 = out3\n",
    "        \n",
    "        # Increase the row and col by a factor of 2\n",
    "        hyper_out5 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1 ,output_padding=1).to(device)\n",
    "        hyper_out5 = hyper_out5(out5)\n",
    "        \n",
    "        hyper_out = torch.cat((hyper_out1,out3,hyper_out5),dim=1)\n",
    "\n",
    "        return hyper_out\n",
    "    \n",
    "class FeatureExtractor_hyperV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input is (b,3,256,256)\n",
    "        \n",
    "        self.dropout_p = 0.3\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            self.conv_bnorm_relu(in_channels=3, out_channels=64),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout(p=self.dropout_p),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            self.conv_bnorm_relu(in_channels=64, out_channels=128),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout(p=self.dropout_p),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            self.conv_bnorm_relu(in_channels=128, out_channels=64),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout(p=self.dropout_p),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img_data):\n",
    "        \n",
    "        img_data = img_data.float()        \n",
    "\n",
    "        out1 = self.block1(img_data)\n",
    "        \n",
    "        out2 = self.block2(out1)\n",
    "        \n",
    "        out3 = self.block3(out2)\n",
    "        \n",
    "        # Assembling the Hyper Feature Map\n",
    "        \n",
    "        # Reduce the row and col by a factor of 1/2\n",
    "        hyper_out1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        hyper_out1 = hyper_out1(out1)\n",
    "        \n",
    "        hyper_out2 = out2\n",
    "        \n",
    "        # Increase the row and col by a factor of 2\n",
    "        hyper_out3 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1 ,output_padding=1).to(device)\n",
    "        hyper_out3 = hyper_out3(out3)\n",
    "        \n",
    "        hyper_out = torch.cat((hyper_out1,out2,hyper_out3),dim=1)\n",
    "        \n",
    "        return hyper_out\n",
    "    \n",
    "    def conv_bnorm_relu(self, in_channels, out_channels):\n",
    "        \n",
    "        conv_bnorm_relu = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        return conv_bnorm_relu\n",
    "    \n",
    "class FeatureExtractor_resnet50hyper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input is (b,3,256,256)\n",
    "        \n",
    "        # Load the pretrained ResNet-50 model\n",
    "        model = models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Flatten all modules recursively\n",
    "        self.all_modules = self.flatten_modules_resnet50hyper(model)\n",
    "        self.all_modules = self.all_modules[:27]\n",
    "        # Remove module 11 and 12 since these are only for the residual connection which is not used\n",
    "        del self.all_modules[11:13]  \n",
    "        \n",
    "        self.all_modules_seq = nn.Sequential(*self.all_modules)\n",
    "        \n",
    "    def forward(self, img_data):\n",
    "        \n",
    "        img_data = img_data.float()        \n",
    "        \n",
    "        out3  = nn.Sequential(*self.all_modules[0:4])(img_data) # After 1 convolution\n",
    "        \n",
    "        out7  = nn.Sequential(*self.all_modules[4:8])(out3) # After 3 convolutions\n",
    "        \n",
    "        out14 = nn.Sequential(*self.all_modules[8:15])(out7) # After 6 convolutions\n",
    "        \n",
    "        out21 = nn.Sequential(*self.all_modules[15:22])(out14) # After 9 convolutions\n",
    "        \n",
    "        out = torch.cat((out3, out7, out14, out21),dim=1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def flatten_modules_resnet50hyper(self,model):\n",
    "        modules = []\n",
    "        for m in list(model.children()):\n",
    "            if isinstance(m, (nn.Sequential, nn.ModuleList, nn.ModuleDict)):\n",
    "                modules.extend(self.flatten_modules_resnet50hyper(m))\n",
    "            elif isinstance(m, nn.Module):\n",
    "                if isinstance(m, models.resnet.Bottleneck):\n",
    "                    for sub_module in self.flatten_modules_resnet50hyper(m):\n",
    "                        modules.append(sub_module)\n",
    "                else:\n",
    "                    modules.append(m)\n",
    "        return modules\n",
    "#############\n",
    "\n",
    "\n",
    "class ProposalModule(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim=512, n_anchors=9, p_dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.n_anchors = n_anchors\n",
    "        self.conv1 = nn.Conv2d(in_features, hidden_dim, kernel_size=3, padding=1) \n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        \n",
    "        # EDIT: stride can be changed!\n",
    "        self.conf_head = nn.Conv2d(hidden_dim, n_anchors, kernel_size=1)\n",
    "        self.reg_head = nn.Conv2d(hidden_dim, n_anchors * 4, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, feature_map, pos_anc_ind=None, neg_anc_ind=None, pos_anc_coords=None):\n",
    "        # determine mode\n",
    "        if pos_anc_ind is None or neg_anc_ind is None or pos_anc_coords is None:\n",
    "            mode = 'eval'\n",
    "        else:\n",
    "            mode = 'train'\n",
    "            \n",
    "        out = self.conv1(feature_map)\n",
    "        out = F.relu(self.dropout(out))\n",
    "        \n",
    "        reg_offsets_pred = self.reg_head(out) # (B, A*4, hmap, wmap)\n",
    "        conf_scores_pred = self.conf_head(out) # (B, A, hmap, wmap)\n",
    "        \n",
    "        if mode == 'train': \n",
    "            # get conf scores \n",
    "            conf_scores_pos = conf_scores_pred.flatten()[pos_anc_ind]\n",
    "            conf_scores_neg = conf_scores_pred.flatten()[neg_anc_ind]\n",
    "            # get offsets for +ve anchors\n",
    "            offsets_pos = reg_offsets_pred.contiguous().view(-1, 4)[pos_anc_ind]\n",
    "            # generate proposals using offsets\n",
    "            proposals = generate_proposals(pos_anc_coords, offsets_pos)\n",
    "            # EDIT: added conf_scores_pred and reg_offsets_pred\n",
    "            return conf_scores_pred,reg_offsets_pred, conf_scores_pos, conf_scores_neg, offsets_pos, proposals \n",
    "            \n",
    "        elif mode == 'eval':\n",
    "            return conf_scores_pred, reg_offsets_pred\n",
    "\n",
    "class RegionProposalNetwork(nn.Module):\n",
    "    def __init__(self, img_size, out_size, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_height, self.img_width = img_size\n",
    "        self.out_h, self.out_w = out_size\n",
    "        \n",
    "        # downsampling scale factor \n",
    "        self.width_scale_factor = self.img_width // self.out_w\n",
    "        self.height_scale_factor = self.img_height // self.out_h \n",
    "        \n",
    "        # ANCHOR BOX DEFINITION\n",
    "        # scales and ratios for anchor boxes \n",
    "        self.anc_scales = [10] #[5,10] #[2, 4, 6] # [5,10]\n",
    "        self.anc_ratios = [1]#[0.5,1,2]# [0.5, 1, 1.5] # [1,2,0.5]\n",
    "        self.n_anc_boxes = len(self.anc_scales) * len(self.anc_ratios)\n",
    "        \n",
    "        self.n_anc_boxes_total = self.n_anc_boxes*self.out_h*self.out_w\n",
    "        \n",
    "        # IoU thresholds for +ve and -ve anchors\n",
    "        self.pos_thresh = 0.7\n",
    "        self.neg_thresh = 0.3\n",
    "        \n",
    "        # weights for loss\n",
    "        self.w_conf = 1\n",
    "        self.w_reg = 5\n",
    "        \n",
    "        self.feature_extractor = FeatureExtractor().to(device) # EDIT\n",
    "        self.proposal_module = ProposalModule(out_channels, n_anchors=self.n_anc_boxes).to(device) # EDIT\n",
    "        \n",
    "    def forward(self, images, gt_bboxes): # EDIT: removed gt_classes\n",
    "        batch_size = images.size(dim=0)\n",
    "        feature_map = self.feature_extractor(images)\n",
    "        \n",
    "        # generate anchors\n",
    "        anc_pts_x, anc_pts_y = gen_anc_centers(out_size=(self.out_h, self.out_w))\n",
    "        anc_base = gen_anc_base(anc_pts_x, anc_pts_y, self.anc_scales, self.anc_ratios, (self.out_h, self.out_w))\n",
    "        anc_boxes_all = anc_base.repeat(batch_size, 1, 1, 1, 1)\n",
    "        \n",
    "        # get positive and negative anchors amongst other things\n",
    "        gt_bboxes_proj = project_bboxes(gt_bboxes, self.width_scale_factor, self.height_scale_factor, mode='p2a')\n",
    "        \n",
    "        # EDIT: Removed GT_class_pos right after GT_offsets\n",
    "        positive_anc_ind, negative_anc_ind, GT_conf_scores, \\\n",
    "        GT_offsets, positive_anc_coords, \\\n",
    "        negative_anc_coords, positive_anc_ind_sep = get_req_anchors(anc_boxes_all, gt_bboxes_proj)\n",
    "        \n",
    "        # pass through the proposal module\n",
    "        conf_scores_pred, reg_offsets_pred, conf_scores_pos, conf_scores_neg, offsets_pos, proposals \\\n",
    "        = self.proposal_module(feature_map, positive_anc_ind, negative_anc_ind, positive_anc_coords)\n",
    "        \n",
    "        cls_loss = calc_cls_loss(conf_scores_pos, conf_scores_neg, batch_size)\n",
    "        reg_loss = calc_bbox_reg_loss(GT_offsets, offsets_pos, batch_size)\n",
    "        \n",
    "        # confusion = calc_confusion(conf_scores_pred.flatten(),positive_anc_ind)\n",
    "        \n",
    "        total_rpn_loss = self.w_conf * cls_loss + self.w_reg * reg_loss\n",
    "        \n",
    "        # EDIT: Removed GT_class_pos right after positive_anc_ind_sep\n",
    "        return total_rpn_loss, feature_map, proposals, positive_anc_ind_sep #, confusion\n",
    "    \n",
    "    def inference(self, images, conf_thresh=0.5, nms_thresh=0.4): # EDIT: CHOOSE TOP 10 PROPOSALS\n",
    "        with torch.no_grad():\n",
    "            batch_size = images.size(dim=0)\n",
    "            feature_map = self.feature_extractor(images)\n",
    "            \n",
    "            # generate anchors\n",
    "            anc_pts_x, anc_pts_y = gen_anc_centers(out_size=(self.out_h, self.out_w))\n",
    "            anc_base = gen_anc_base(anc_pts_x, anc_pts_y, self.anc_scales, self.anc_ratios, (self.out_h, self.out_w))\n",
    "            anc_boxes_all = anc_base.repeat(batch_size, 1, 1, 1, 1)\n",
    "            anc_boxes_flat = anc_boxes_all.reshape(batch_size, -1, 4) # EDIT\n",
    "\n",
    "            # get conf scores and offsets\n",
    "            conf_scores_pred, offsets_pred = self.proposal_module(feature_map)\n",
    "            conf_scores_pred = conf_scores_pred.reshape(batch_size, -1)\n",
    "            offsets_pred = offsets_pred.reshape(batch_size, -1, 4) # EDIT\n",
    "\n",
    "            # filter out proposals based on conf threshold and nms threshold for each image\n",
    "            proposals_final = []\n",
    "            conf_scores_final = []\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                conf_scores = torch.sigmoid(conf_scores_pred[i])\n",
    "                offsets = offsets_pred[i]\n",
    "                anc_boxes = anc_boxes_flat[i]\n",
    "                proposals = generate_proposals(anc_boxes.to(device), offsets.to(device))\n",
    "                # filter based on confidence threshold\n",
    "                conf_idx = torch.where(conf_scores >= conf_thresh)[0]\n",
    "                \n",
    "                conf_scores_pos = conf_scores[conf_idx]\n",
    "                proposals_pos = proposals[conf_idx]\n",
    "                # filter based on nms threshold\n",
    "                nms_idx = ops.nms(proposals_pos, conf_scores_pos, nms_thresh)\n",
    "                conf_scores_pos = conf_scores_pos[nms_idx]\n",
    "                proposals_pos = proposals_pos[nms_idx]\n",
    "                \n",
    "                # EDIT: The conf_scores_pos are already sorted, so now we choose the top 10 proposals\n",
    "                # conf_scores_pos = conf_scores_pos[:10]\n",
    "                # proposals_pos = proposals_pos[:10]\n",
    "                \n",
    "                proposals_final.append(proposals_pos)\n",
    "                conf_scores_final.append(conf_scores_pos)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        return proposals_final, conf_scores_final, feature_map\n",
    "    \n",
    "class ClassificationModule(nn.Module): # Not used\n",
    "    def __init__(self, out_channels, n_classes, roi_size, hidden_dim=512, p_dropout=0.3):\n",
    "        super().__init__()        \n",
    "        self.roi_size = roi_size\n",
    "        # hidden network\n",
    "        self.avg_pool = nn.AvgPool2d(self.roi_size)\n",
    "        self.fc = nn.Linear(out_channels, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        \n",
    "        # define classification head\n",
    "        self.cls_head = nn.Linear(hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self, feature_map, proposals_list, gt_classes=None):\n",
    "        \n",
    "        if gt_classes is None:\n",
    "            mode = 'eval'\n",
    "        else:\n",
    "            mode = 'train'\n",
    "        \n",
    "        # apply roi pooling on proposals followed by avg pooling\n",
    "        roi_out = ops.roi_pool(feature_map, proposals_list, self.roi_size)\n",
    "        roi_out = self.avg_pool(roi_out)\n",
    "        \n",
    "        # flatten the output\n",
    "        roi_out = roi_out.squeeze(-1).squeeze(-1)\n",
    "        \n",
    "        # pass the output through the hidden network\n",
    "        out = self.fc(roi_out)\n",
    "        out = F.relu(self.dropout(out))\n",
    "        \n",
    "        # get the classification scores\n",
    "        cls_scores = self.cls_head(out)\n",
    "        \n",
    "        if mode == 'eval':\n",
    "            return cls_scores\n",
    "        \n",
    "        # compute cross entropy loss\n",
    "        cls_loss = F.cross_entropy(cls_scores, gt_classes.long())\n",
    "        \n",
    "        return cls_loss\n",
    "    \n",
    "class TwoStageDetector(nn.Module): # Not used\n",
    "    def __init__(self, img_size, out_size, out_channels, n_classes, roi_size):\n",
    "        super().__init__() \n",
    "        self.rpn = RegionProposalNetwork(img_size, out_size, out_channels)\n",
    "        self.classifier = ClassificationModule(out_channels, n_classes, roi_size)\n",
    "        \n",
    "    def forward(self, images, gt_bboxes, gt_classes):\n",
    "        total_rpn_loss, feature_map, proposals, \\\n",
    "        positive_anc_ind_sep, GT_class_pos = self.rpn(images, gt_bboxes, gt_classes)\n",
    "        \n",
    "        # get separate proposals for each sample\n",
    "        pos_proposals_list = []\n",
    "        batch_size = images.size(dim=0)\n",
    "        for idx in range(batch_size):\n",
    "            proposal_idxs = torch.where(positive_anc_ind_sep == idx)[0]\n",
    "            proposals_sep = proposals[proposal_idxs].detach().clone()\n",
    "            pos_proposals_list.append(proposals_sep)\n",
    "        \n",
    "        cls_loss = self.classifier(feature_map, pos_proposals_list, GT_class_pos)\n",
    "        total_loss = cls_loss + total_rpn_loss\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def inference(self, images, conf_thresh=0.5, nms_thresh=0.7):\n",
    "        batch_size = images.size(dim=0)\n",
    "        proposals_final, conf_scores_final, feature_map = self.rpn.inference(images, conf_thresh, nms_thresh)\n",
    "        cls_scores = self.classifier(feature_map, proposals_final)\n",
    "        \n",
    "        # convert scores into probability\n",
    "        cls_probs = F.softmax(cls_scores, dim=-1)\n",
    "        # get classes with highest probability\n",
    "        classes_all = torch.argmax(cls_probs, dim=-1)\n",
    "        \n",
    "        classes_final = []\n",
    "        # slice classes to map to their corresponding image\n",
    "        c = 0\n",
    "        for i in range(batch_size):\n",
    "            n_proposals = len(proposals_final[i]) # get the number of proposals for each image\n",
    "            classes_final.append(classes_all[c: c+n_proposals])\n",
    "            c += n_proposals\n",
    "            \n",
    "        return proposals_final, conf_scores_final, classes_final\n",
    "\n",
    "# ------------------- Loss Utils ----------------------\n",
    "\n",
    "def calc_cls_loss(conf_scores_pos, conf_scores_neg, batch_size):\n",
    "    target_pos = torch.ones_like(conf_scores_pos)\n",
    "    target_neg = torch.zeros_like(conf_scores_neg)\n",
    "    \n",
    "    target = torch.cat((target_pos, target_neg))\n",
    "    inputs = torch.cat((conf_scores_pos, conf_scores_neg))\n",
    "     \n",
    "    loss = F.binary_cross_entropy_with_logits(inputs, target, reduction='sum') #* 1. / batch_size # EDIT\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def calc_bbox_reg_loss(gt_offsets, reg_offsets_pos, batch_size):\n",
    "    assert gt_offsets.size() == reg_offsets_pos.size()\n",
    "    loss = F.smooth_l1_loss(reg_offsets_pos, gt_offsets, reduction='sum') #* 1. / batch_size # EDIT\n",
    "    return loss\n",
    "\n",
    "### JONAS ###\n",
    "def calc_confusion(conf_scores_pred,positive_anc_ind):\n",
    "    n = len(conf_scores_pred)\n",
    "    test = torch.zeros(n).to(device)\n",
    "    test_np = positive_anc_ind.detach().cpu().numpy()\n",
    "    test[test_np] = 1\n",
    "    test = test.to(device)\n",
    "\n",
    "    metric = BinaryStatScores(threshold = 0.5).to(device)\n",
    "    confusion = metric(conf_scores_pred,test)\n",
    "    \n",
    "    # [tp, fp, tn, fn, sup] (sup stands for support and equals tp + fn)\n",
    "    return confusion[:-1]\n",
    "    \n",
    "def calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='sum'):\n",
    "      \n",
    "    n = len(gt_bboxes_proj)\n",
    "    \n",
    "    iou_mat = []\n",
    "    positive_prop_mask = []\n",
    "    fn = []\n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    \n",
    "    # loop over images\n",
    "    for i in range(n):\n",
    "        gt_bboxes_proj_unpadded = unpad_BB(gt_bboxes_proj[i])\n",
    "\n",
    "        iou_mat.append(ops.box_iou(proposals_final[i].to(device), gt_bboxes_proj_unpadded.to(device)))\n",
    "\n",
    "        max_iou_per_gt_box, _ = iou_mat[i].max(dim=1, keepdim=True)\n",
    "\n",
    "        positive_prop_mask.append(torch.logical_and(iou_mat[i] > pos_thresh, max_iou_per_gt_box > 0))\n",
    "\n",
    "\n",
    "        test = positive_prop_mask[i].sum(dim=0)\n",
    "        item1 = len(test) - torch.count_nonzero(test)\n",
    "        fn.append(item1)\n",
    "\n",
    "        \n",
    "        item2 = positive_prop_mask[i].sum()\n",
    "        tp.append(item2)\n",
    "\n",
    "        item3 = positive_prop_mask[i].shape[0]-tp[i]\n",
    "        fp.append(item3)\n",
    "        \n",
    "        item4 = n_anc_boxes_total - (item1+item2+item3)\n",
    "        tn.append(item4)\n",
    "    \n",
    "    if list_or_sum == 'sum':\n",
    "        tp = torch.sum(torch.stack(tp))\n",
    "        fp = torch.sum(torch.stack(fp))\n",
    "        fn = torch.sum(torch.stack(fn))\n",
    "        tn = torch.sum(torch.stack(tn))\n",
    "    elif list_or_sum == 'list':\n",
    "        tp = torch.stack(tp)\n",
    "        fp = torch.stack(fp)\n",
    "        fn = torch.stack(fn)\n",
    "        tn = torch.stack(tn)\n",
    "    \n",
    "    return tp, fp, fn, tn\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c5f1c41",
   "metadata": {
    "code_folding": [
     0,
     3,
     53,
     67,
     75,
     98,
     115,
     140,
     161,
     271,
     291,
     299,
     321
    ]
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%%  UTILS  %%%%%%%%%% #\n",
    "# -------------- Data Utils -------------------\n",
    "\n",
    "def parse_annotation(annotation_path, image_dir, img_size): # Not used\n",
    "    '''\n",
    "    Traverse the xml tree, get the annotations, and resize them to the scaled image size\n",
    "    '''\n",
    "    img_h, img_w = img_size\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        tree = ET.parse(f)\n",
    "\n",
    "    root = tree.getroot()  \n",
    "    \n",
    "    img_paths = []\n",
    "    gt_boxes_all = []\n",
    "    gt_classes_all = []\n",
    "    # get image paths\n",
    "    for object_ in root.findall('image'):\n",
    "        img_path = os.path.join(image_dir, object_.get(\"name\"))\n",
    "        img_paths.append(img_path)\n",
    "      \n",
    "        # get raw image size    \n",
    "        orig_w = int(object_.get(\"width\"))\n",
    "        orig_h = int(object_.get(\"height\"))\n",
    "            \n",
    "        # get bboxes and their labels   \n",
    "        groundtruth_boxes = []\n",
    "        groundtruth_classes = []\n",
    "        for box_ in object_.findall('box'):\n",
    "            xmin = float(box_.get(\"xtl\"))\n",
    "            ymin = float(box_.get(\"ytl\"))\n",
    "            xmax = float(box_.get(\"xbr\"))\n",
    "            ymax = float(box_.get(\"ybr\"))\n",
    "        \n",
    "            # rescale bboxes\n",
    "            bbox = torch.Tensor([xmin, ymin, xmax, ymax])\n",
    "            bbox[[0, 2]] = bbox[[0, 2]] * img_w/orig_w\n",
    "            bbox[[1, 3]] = bbox[[1, 3]] * img_h/orig_h\n",
    "        \n",
    "            groundtruth_boxes.append(bbox.tolist())\n",
    "\n",
    "            # get labels\n",
    "            label = box_.get(\"label\")\n",
    "            groundtruth_classes.append(label)\n",
    "\n",
    "        gt_boxes_all.append(torch.Tensor(groundtruth_boxes))\n",
    "        gt_classes_all.append(groundtruth_classes)\n",
    "                \n",
    "    return gt_boxes_all, gt_classes_all, img_paths\n",
    "\n",
    "# -------------- Prepocessing utils ----------------\n",
    "\n",
    "def calc_gt_offsets(pos_anc_coords, gt_bbox_mapping):\n",
    "    pos_anc_coords = ops.box_convert(pos_anc_coords, in_fmt='xyxy', out_fmt='cxcywh')\n",
    "    gt_bbox_mapping = ops.box_convert(gt_bbox_mapping, in_fmt='xyxy', out_fmt='cxcywh')\n",
    "\n",
    "    gt_cx, gt_cy, gt_w, gt_h = gt_bbox_mapping[:, 0], gt_bbox_mapping[:, 1], gt_bbox_mapping[:, 2], gt_bbox_mapping[:, 3]\n",
    "    anc_cx, anc_cy, anc_w, anc_h = pos_anc_coords[:, 0], pos_anc_coords[:, 1], pos_anc_coords[:, 2], pos_anc_coords[:, 3]\n",
    "\n",
    "    tx_ = (gt_cx - anc_cx)/anc_w\n",
    "    ty_ = (gt_cy - anc_cy)/anc_h\n",
    "    tw_ = torch.log(gt_w / anc_w)\n",
    "    th_ = torch.log(gt_h / anc_h)\n",
    "\n",
    "    return torch.stack([tx_, ty_, tw_, th_], dim=-1)\n",
    "\n",
    "def gen_anc_centers(out_size): # EDIT THIS FOR CHANGING STRIDE!\n",
    "    out_h, out_w = out_size\n",
    "    \n",
    "    anc_pts_x = torch.arange(0, out_w, device=device) + 0.5 # EDIT\n",
    "    anc_pts_y = torch.arange(0, out_h, device=device) + 0.5 # EDIT\n",
    "    \n",
    "    return anc_pts_x, anc_pts_y\n",
    "\n",
    "def project_bboxes(bboxes, width_scale_factor, height_scale_factor, mode='a2p'):\n",
    "    assert mode in ['a2p', 'p2a']\n",
    "    \n",
    "    batch_size = bboxes.size(dim=0)\n",
    "    proj_bboxes = bboxes.clone().reshape(batch_size, -1, 4)\n",
    "    invalid_bbox_mask = (proj_bboxes == -1) # indicating padded bboxes\n",
    "    proj_bboxes = proj_bboxes.double() # EDIT: Jonas added this\n",
    "    \n",
    "    if mode == 'a2p':\n",
    "        # activation map to pixel image\n",
    "        proj_bboxes[:, :, [0, 2]] *= width_scale_factor\n",
    "        proj_bboxes[:, :, [1, 3]] *= height_scale_factor\n",
    "    else:\n",
    "        # pixel image to activation map\n",
    "        proj_bboxes[:, :, [0, 2]] /= width_scale_factor\n",
    "        proj_bboxes[:, :, [1, 3]] /= height_scale_factor\n",
    "        \n",
    "    proj_bboxes = proj_bboxes.int() # EDIT: Jonas added this\n",
    "    proj_bboxes.masked_fill_(invalid_bbox_mask, -1) # fill padded bboxes back with -1\n",
    "    proj_bboxes.resize_as_(bboxes)\n",
    "    \n",
    "    return proj_bboxes\n",
    "\n",
    "def generate_proposals(anchors, offsets):\n",
    "   \n",
    "    # change format of the anchor boxes from 'xyxy' to 'cxcywh'\n",
    "    anchors = ops.box_convert(anchors, in_fmt='xyxy', out_fmt='cxcywh')\n",
    "    \n",
    "    # apply offsets to anchors to create proposals\n",
    "    proposals_ = torch.zeros_like(anchors).to(device) # EDIT\n",
    "    proposals_[:,0] = anchors[:,0] + offsets[:,0]*anchors[:,2]\n",
    "    proposals_[:,1] = anchors[:,1] + offsets[:,1]*anchors[:,3]\n",
    "    proposals_[:,2] = anchors[:,2] * torch.exp(offsets[:,2])\n",
    "    proposals_[:,3] = anchors[:,3] * torch.exp(offsets[:,3])\n",
    "\n",
    "    # change format of proposals back from 'cxcywh' to 'xyxy'\n",
    "    proposals = ops.box_convert(proposals_, in_fmt='cxcywh', out_fmt='xyxy') # \n",
    "\n",
    "    return proposals\n",
    "\n",
    "def gen_anc_base(anc_pts_x, anc_pts_y, anc_scales, anc_ratios, out_size):\n",
    "    n_anc_boxes = len(anc_scales) * len(anc_ratios)\n",
    "    anc_base = torch.zeros(1, anc_pts_x.size(dim=0) \\\n",
    "                              , anc_pts_y.size(dim=0), n_anc_boxes, 4,device=device) # shape - [1, Hmap, Wmap, n_anchor_boxes, 4]\n",
    "    # EDIT\n",
    "    for ix, xc in enumerate(anc_pts_x):\n",
    "        for jx, yc in enumerate(anc_pts_y):\n",
    "            anc_boxes = torch.zeros((n_anc_boxes, 4),device=device) # EDIT\n",
    "            c = 0\n",
    "            for i, scale in enumerate(anc_scales):\n",
    "                for j, ratio in enumerate(anc_ratios):\n",
    "                    w = scale * ratio\n",
    "                    h = scale\n",
    "\n",
    "                    xmin = xc - w / 2\n",
    "                    ymin = yc - h / 2\n",
    "                    xmax = xc + w / 2\n",
    "                    ymax = yc + h / 2\n",
    "                    anc_boxes[c, :] = torch.Tensor([xmin, ymin, xmax, ymax])\n",
    "                    c += 1\n",
    "\n",
    "            anc_base[:, ix, jx, :] = ops.clip_boxes_to_image(anc_boxes, size=out_size)\n",
    "        \n",
    "    return anc_base\n",
    "\n",
    "def get_iou_mat(batch_size, anc_boxes_all, gt_bboxes_all):\n",
    "    \n",
    "    \n",
    "    # flatten anchor boxes\n",
    "    anc_boxes_flat = anc_boxes_all.reshape(batch_size, -1, 4)\n",
    "    # get total anchor boxes for a single image\n",
    "    tot_anc_boxes = anc_boxes_flat.size(dim=1)\n",
    "    \n",
    "    # create a placeholder to compute IoUs amongst the boxes\n",
    "    ious_mat = torch.zeros((batch_size, tot_anc_boxes, gt_bboxes_all.size(dim=1))).to(device) # EDIT\n",
    "\n",
    "    # compute IoU of the anc boxes with the gt boxes for all the images\n",
    "    for i in range(batch_size):\n",
    "        gt_bboxes = gt_bboxes_all[i] # need to change format to (x1,y1,x2,y2)\n",
    "        #gt_bboxes = ops.box_convert(gt_bboxes,'cxcywh','xyxy') # EDIT: Jonas added this\n",
    "        \n",
    "        anc_boxes = anc_boxes_flat[i] \n",
    "        ious_mat[i, :] = ops.box_iou(anc_boxes.to(device), gt_bboxes.to(device)) # EDIT\n",
    "        \n",
    "    return ious_mat\n",
    "\n",
    "def get_req_anchors(anc_boxes_all, gt_bboxes_all, pos_thresh=0.7, neg_thresh=0.2):\n",
    "    # EDIT: Jonas removed gt_classes_all (right after gt_bboxes_all)\n",
    "    '''\n",
    "    Prepare necessary data required for training\n",
    "    \n",
    "    Input\n",
    "    ------\n",
    "    anc_boxes_all - torch.Tensor of shape (B, w_amap, h_amap, n_anchor_boxes, 4)\n",
    "        all anchor boxes for a batch of images\n",
    "    gt_bboxes_all - torch.Tensor of shape (B, max_objects, 4)\n",
    "        padded ground truth boxes for a batch of images\n",
    "    gt_classes_all - torch.Tensor of shape (B, max_objects)\n",
    "        padded ground truth classes for a batch of images\n",
    "        \n",
    "    EDIT: We do not have gt_classes_all \n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    positive_anc_ind -  torch.Tensor of shape (n_pos,)\n",
    "        flattened positive indices for all the images in the batch\n",
    "    negative_anc_ind - torch.Tensor of shape (n_pos,)\n",
    "        flattened positive indices for all the images in the batch\n",
    "    GT_conf_scores - torch.Tensor of shape (n_pos,), IoU scores of +ve anchors\n",
    "    GT_offsets -  torch.Tensor of shape (n_pos, 4),\n",
    "        offsets between +ve anchors and their corresponding ground truth boxes\n",
    "    GT_class_pos - torch.Tensor of shape (n_pos,)\n",
    "        mapped classes of +ve anchors\n",
    "    positive_anc_coords - (n_pos, 4) coords of +ve anchors (for visualization)\n",
    "    negative_anc_coords - (n_pos, 4) coords of -ve anchors (for visualization)\n",
    "    positive_anc_ind_sep - list of indices to keep track of +ve anchors\n",
    "    \n",
    "    EDIT: We do not have GT_class_pos\n",
    "    '''\n",
    "    \n",
    "    # get the size and shape parameters\n",
    "    B, w_amap, h_amap, A, _ = anc_boxes_all.shape\n",
    "    N = gt_bboxes_all.shape[1] # max number of groundtruth bboxes in a batch\n",
    "    \n",
    "    # get total number of anchor boxes in a single image\n",
    "    tot_anc_boxes = A * w_amap * h_amap\n",
    "    \n",
    "    # get the iou matrix which contains iou of every anchor box\n",
    "    # against all the groundtruth bboxes in an image\n",
    "    iou_mat = get_iou_mat(B, anc_boxes_all, gt_bboxes_all)\n",
    "    \n",
    "    # for every groundtruth bbox in an image, find the iou \n",
    "    # with the anchor box which it overlaps the most\n",
    "    max_iou_per_gt_box, _ = iou_mat.max(dim=1, keepdim=True)\n",
    "    \n",
    "    # get positive anchor boxes\n",
    "    \n",
    "    # condition 1: the anchor box with the max iou for every gt bbox\n",
    "    positive_anc_mask = torch.logical_and(iou_mat == max_iou_per_gt_box, max_iou_per_gt_box > 0) \n",
    "    # condition 2: anchor boxes with iou above a threshold with any of the gt bboxes\n",
    "    positive_anc_mask = torch.logical_or(positive_anc_mask, iou_mat > pos_thresh)\n",
    "    \n",
    "    positive_anc_ind_sep = torch.where(positive_anc_mask)[0] # get separate indices in the batch\n",
    "    # combine all the batches and get the idxs of the +ve anchor boxes\n",
    "    positive_anc_mask = positive_anc_mask.flatten(start_dim=0, end_dim=1)\n",
    "    positive_anc_ind = torch.where(positive_anc_mask)[0]\n",
    "    \n",
    "    # for every anchor box, get the iou and the idx of the\n",
    "    # gt bbox it overlaps with the most\n",
    "    max_iou_per_anc, max_iou_per_anc_ind = iou_mat.max(dim=-1)\n",
    "    max_iou_per_anc = max_iou_per_anc.flatten(start_dim=0, end_dim=1)\n",
    "    \n",
    "    # get iou scores of the +ve anchor boxes\n",
    "    GT_conf_scores = max_iou_per_anc[positive_anc_ind]\n",
    "    \n",
    "    # get gt classes of the +ve anchor boxes\n",
    "    \n",
    "    # EDIT: Jonas commented this section out\n",
    "    # # expand gt classes to map against every anchor box\n",
    "    # gt_classes_expand = gt_classes_all.view(B, 1, N).expand(B, tot_anc_boxes, N)\n",
    "    # # for every anchor box, consider only the class of the gt bbox it overlaps with the most\n",
    "    # GT_class = torch.gather(gt_classes_expand, -1, max_iou_per_anc_ind.unsqueeze(-1)).squeeze(-1)\n",
    "    # # combine all the batches and get the mapped classes of the +ve anchor boxes\n",
    "    # GT_class = GT_class.flatten(start_dim=0, end_dim=1)\n",
    "    # GT_class_pos = GT_class[positive_anc_ind]\n",
    "    \n",
    "    # get gt bbox coordinates of the +ve anchor boxes\n",
    "    \n",
    "    # expand all the gt bboxes to map against every anchor box\n",
    "    gt_bboxes_expand = gt_bboxes_all.view(B, 1, N, 4).expand(B, tot_anc_boxes, N, 4)\n",
    "    # for every anchor box, consider only the coordinates of the gt bbox it overlaps with the most\n",
    "    GT_bboxes = torch.gather(gt_bboxes_expand, -2, max_iou_per_anc_ind.reshape(B, tot_anc_boxes, 1, 1).repeat(1, 1, 1, 4))\n",
    "    # combine all the batches and get the mapped gt bbox coordinates of the +ve anchor boxes\n",
    "    GT_bboxes = GT_bboxes.flatten(start_dim=0, end_dim=2)\n",
    "    GT_bboxes_pos = GT_bboxes[positive_anc_ind]\n",
    "    \n",
    "    # get coordinates of +ve anc boxes\n",
    "    anc_boxes_flat = anc_boxes_all.flatten(start_dim=0, end_dim=-2).to(device) # flatten all the anchor boxes # EDIT\n",
    "    positive_anc_coords = anc_boxes_flat[positive_anc_ind]\n",
    "    \n",
    "    # calculate gt offsets\n",
    "    GT_offsets = calc_gt_offsets(positive_anc_coords, GT_bboxes_pos)\n",
    "    \n",
    "    # get -ve anchors\n",
    "    \n",
    "    # condition: select the anchor boxes with max iou less than the threshold\n",
    "    negative_anc_mask = (max_iou_per_anc < neg_thresh)\n",
    "    negative_anc_ind = torch.where(negative_anc_mask)[0]\n",
    "    # sample -ve samples to match the +ve samples\n",
    "    negative_anc_ind = negative_anc_ind[torch.randint(0, negative_anc_ind.shape[0], (positive_anc_ind.shape[0],))]\n",
    "    negative_anc_coords = anc_boxes_flat[negative_anc_ind]\n",
    "    \n",
    "    # EDIT: Jonas removed GT_class_pos (right after GT_offsets)\n",
    "    return positive_anc_ind, negative_anc_ind, GT_conf_scores, GT_offsets, \\\n",
    "         positive_anc_coords, negative_anc_coords, positive_anc_ind_sep\n",
    "\n",
    "def unpad_BB(BB_padded_tensor): # Jonas\n",
    "    \n",
    "    BB_padded_np = BB_padded_tensor.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    if np.min(BB_padded_np) == -1:\n",
    "        idx = np.argmin(BB_padded_np,0)[0]\n",
    "    else:\n",
    "        # if there is no padding, then return the input\n",
    "        return BB_padded_tensor\n",
    "    \n",
    "        \n",
    "    BB_unpadded_np = BB_padded_np[0:idx,:]\n",
    "    \n",
    "    BB_unpadded_tensor = torch.from_numpy(BB_unpadded_np)\n",
    "    \n",
    "    return BB_unpadded_tensor\n",
    "\n",
    "# # -------------- Visualization utils ----------------\n",
    "\n",
    "def display_img(img_data, fig, axes):\n",
    "    for i, img in enumerate(img_data):\n",
    "        if type(img) == torch.Tensor:\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img.astype('uint8'))\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "def display_bbox(bboxes, fig, ax, classes=None, in_format='xyxy', color='y', line_width=3):\n",
    "    if type(bboxes) == np.ndarray:\n",
    "        bboxes = torch.from_numpy(bboxes)\n",
    "    if classes:\n",
    "        assert len(bboxes) == len(classes)\n",
    "    # convert boxes to xywh format\n",
    "    bboxes = ops.box_convert(bboxes, in_fmt=in_format, out_fmt='xywh')\n",
    "    c = 0\n",
    "    for box in bboxes:\n",
    "        x, y, w, h = box.numpy()\n",
    "        # display bounding box\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=line_width, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        # display category\n",
    "        if classes:\n",
    "            if classes[c] == 'pad':\n",
    "                continue\n",
    "            ax.text(x + 5, y + 20, classes[c], bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "        c += 1\n",
    "        \n",
    "    return fig, ax\n",
    "\n",
    "def display_grid(x_points, y_points, fig, ax, special_point=None):\n",
    "    # plot grid\n",
    "    for x in x_points:\n",
    "        for y in y_points:\n",
    "            ax.scatter(x, y, color=\"w\", marker='+')\n",
    "            \n",
    "    # plot a special point we want to emphasize on the grid\n",
    "    if special_point:\n",
    "        x, y = special_point\n",
    "        ax.scatter(x, y, color=\"red\", marker='+')\n",
    "        \n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02d9e21b",
   "metadata": {
    "code_folding": [
     0,
     2,
     16,
     43,
     72,
     96,
     118,
     213,
     228,
     321,
     515,
     573,
     700,
     777,
     841,
     922,
     1004,
     1088,
     1170,
     1251,
     1332,
     1385,
     1438,
     1470,
     1508,
     1607,
     1658,
     1714,
     1743,
     1786,
     1808,
     1901
    ]
   },
   "outputs": [],
   "source": [
    "# %%%%%%%%%%  JONAS  %%%%%%%%%% #\n",
    "\n",
    "def flatten_modules(model):\n",
    "    # Flatten modules of a pre-designed NN\n",
    "    modules = []\n",
    "    for m in list(model.children()):\n",
    "        if isinstance(m, (nn.Sequential, nn.ModuleList, nn.ModuleDict)):\n",
    "            modules.extend(flatten_modules(m))\n",
    "        elif isinstance(m, nn.Module):\n",
    "            if isinstance(m, models.resnet.Bottleneck):\n",
    "                for sub_module in flatten_modules(m):\n",
    "                    modules.append(sub_module)\n",
    "            else:\n",
    "                modules.append(m)\n",
    "    return modules\n",
    "\n",
    "def init_RPN(name):\n",
    "    # Initializes Region Proposal Network\n",
    "    img_size = (256,256)\n",
    "    out_size = (64,64)\n",
    "    out_channels = 256\n",
    "    \n",
    "    RPN = RegionProposalNetwork(img_size, out_size, out_channels)\n",
    "    RPN = RPN.to(device)\n",
    "       \n",
    "    \n",
    "    if name.find('hyper') != -1:\n",
    "        \n",
    "        if name.find('hyperV2') != -1:\n",
    "            RPN.feature_extractor = FeatureExtractor_hyperV2().to(device)\n",
    "            \n",
    "        elif name.find('resnet50hyper') != -1:\n",
    "            RPN.feature_extractor = FeatureExtractor_resnet50hyper().to(device)\n",
    "            \n",
    "        else:\n",
    "            RPN.feature_extractor = FeatureExtractor_hyper().to(device)\n",
    "        \n",
    "    \n",
    "    if name.find('random') != -1:\n",
    "        RPN.feature_extractor = FeatureExtractor_random().to(device)   \n",
    "    \n",
    "    return RPN\n",
    "   \n",
    "def init_file_root_and_list(name):\n",
    "    \n",
    "    # For name = 'example'\n",
    "    # 'example'          will use the dataset: augmentedData\n",
    "    # 'example_big'      will use the dataset: augmentedData_big\n",
    "    # 'example_hard'     will use the dataset: augmentedData_hard\n",
    "    # 'example_hard_big' will use the dataset: augmentedData_hard_big\n",
    "    \n",
    "    file_root = \"/scratch/s204219/augmentedData\"\n",
    "    \n",
    "\n",
    "    hard_logic = name.find('hard')\n",
    "    \n",
    "    if hard_logic != -1:\n",
    "        file_root = file_root + '_hard'\n",
    "    else:\n",
    "        file_root = file_root\n",
    "    #######################################\n",
    "    big_logic = name.find('big')\n",
    "    \n",
    "    if big_logic != -1:\n",
    "        file_list = np.arange(dsn,dsn+100000)\n",
    "        file_root = file_root + '_big'\n",
    "    else:\n",
    "        file_list = np.arange(dsn,dsn+40000)\n",
    "        file_root = file_root\n",
    "    \n",
    "    return file_root, file_list\n",
    "\n",
    "def load_data_split(name):\n",
    "    \n",
    "    file_root = \"/scratch/s204219/augmentedData\"\n",
    "    \n",
    "    hard_logic = name.find('hard')\n",
    "    \n",
    "    if hard_logic != -1:\n",
    "        file_root = file_root + '_hard'\n",
    "   \n",
    "    #######################################\n",
    "    big_logic = name.find('big')\n",
    "    \n",
    "    if big_logic != -1:\n",
    "        file_root = file_root + '_big'\n",
    "    \n",
    "    print_str = file_root.split('/')[-1]\n",
    "    print('Using dataset: ' + print_str)\n",
    "    \n",
    "    train_indices = np.load(f'{file_root}/data_split/Index_train.npy')\n",
    "    val_indices   = np.load(f'{file_root}/data_split/Index_val.npy')\n",
    "    test_indices  = np.load(f'{file_root}/data_split/Index_test.npy')\n",
    "\n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "def create_train_val_test_split(file_list, val_ratio, test_ratio, name, save_path, save=False):\n",
    "    \n",
    "            \n",
    "    indices = file_list\n",
    "    dataset_size = len(indices)\n",
    "\n",
    "    val_split  = int(np.round(val_ratio  * dataset_size))\n",
    "    test_split = int(np.round(test_ratio * dataset_size))\n",
    "    train_split= int(dataset_size-(val_split+test_split))\n",
    "\n",
    "    train_indices = np.array(indices[0:train_split])\n",
    "    val_indices   = np.array(indices[train_split:train_split+val_split])\n",
    "    test_indices  = np.array(indices[(train_split+val_split):])\n",
    "    \n",
    "    if save == True:\n",
    "        np.save(f'{save_path}/Index_train_{name}',train_indices)\n",
    "        np.save(f'{save_path}/Index_val_{name}',val_indices)\n",
    "        np.save(f'{save_path}/Index_test_{name}',test_indices)\n",
    "\n",
    "    \n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "def train_model_new(name='example', n_epochs=50, dataset_size=40000, val_ratio=1/7., test_ratio=1/7., save=False, cpm=False):\n",
    "    \n",
    "    # Trains a given RPN model\n",
    "    \n",
    "    save_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    if save == True:\n",
    "        if os.path.exists(save_path) and cpm == False:\n",
    "            choice = input(f\"{name} already exists. Do you want to overwrite it? (y/n)\")\n",
    "            if choice.lower() != 'y':\n",
    "                return\n",
    "            print('overwriting')\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "    \n",
    "    batch_size = 50\n",
    "    \n",
    "    if experiment == False:\n",
    "        np.set_printoptions(precision=3)\n",
    "\n",
    "        file_root, file_list = init_file_root_and_list(name=name)\n",
    "\n",
    "        torch.manual_seed(1)\n",
    "        np.random.seed(1)\n",
    "\n",
    "\n",
    "        # Randomly select numbers from the array\n",
    "        file_list = np.random.choice(file_list, size=dataset_size, replace=False)    \n",
    "\n",
    "        # Creating data indices for training and val splits:\n",
    "        use_old_split = False\n",
    "        if dataset_size == 40000 or dataset_size == 100000:\n",
    "            use_old_split = True\n",
    "\n",
    "        if use_old_split == False:\n",
    "            print('Creating random data split')\n",
    "            train_indices, val_indices, _ = create_train_val_test_split(file_list=file_list, val_ratio=val_ratio, \\\n",
    "                                                                        test_ratio=test_ratio, name=name, \\\n",
    "                                                                        save_path=save_path, save=save)\n",
    "        if use_old_split == True:\n",
    "            train_indices, val_indices, test_indices = load_data_split(name=name)\n",
    "            np.save(f'{save_path}/Index_train_{name}',train_indices)\n",
    "            np.save(f'{save_path}/Index_val_{name}',val_indices)\n",
    "            np.save(f'{save_path}/Index_test_{name}',test_indices)\n",
    "\n",
    "\n",
    "    ##############\n",
    "    # For the experiment: Will more data lead to better performance, along with how much data is needed?\n",
    "    \n",
    "    if experiment == True:\n",
    "        file_root = '/scratch/s204219/augmentedData_hard_big'\n",
    "        train_indices = np.load('/scratch/s204219/augmentedData_hard_big/data_split/Index_train.npy')\n",
    "        val_indices   = np.load('/scratch/s204219/augmentedData_hard_big/data_split/Index_val.npy')\n",
    "        test_indices  = np.load('/scratch/s204219/augmentedData_hard_big/data_split/Index_test.npy')\n",
    "\n",
    "        n_train = len(train_indices)\n",
    "        print(n_train)\n",
    "        name_split = name.split('_')[1]\n",
    "\n",
    "#         number_dict = {'one_hard_big': 1, 'two_hard_big': 2, 'three_hard_big': 3, 'four_hard_big': 4,\\\n",
    "#                        'five_hard_big': 5, 'six_hard_big': 6, 'seven_hard_big': 7, 'eight_hard_big': 8}\n",
    "        number_dict = {'one': 1, 'two': 2, 'three': 3, 'four': 4,\\\n",
    "                       'five': 5, 'six': 6, 'seven': 7, 'eight': 8}\n",
    "        \n",
    "        value = number_dict[name_split]\n",
    "        \n",
    "        # since data_split is 8:1:1\n",
    "        n_train = int(np.round((value*n_train)/10))\n",
    "        print(n_train)\n",
    "        train_indices=train_indices[:n_train]\n",
    "\n",
    "        np.save(f'{save_path}/Index_train_{name}',train_indices)\n",
    "        np.save(f'{save_path}/Index_val_{name}',val_indices)\n",
    "        np.save(f'{save_path}/Index_test_{name}',test_indices)\n",
    "    \n",
    "    ##############\n",
    "    \n",
    "    dataset_train    = UXO_dataset(file_list=train_indices, file_root=file_root)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "    n_train = len(dataset_train)\n",
    "    \n",
    "    dataset_val      = UXO_dataset(file_list=val_indices, file_root=file_root)\n",
    "    dataloader_val   = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "    n_val = len(dataset_val)\n",
    "    \n",
    "    \n",
    "  \n",
    "    RPN = init_RPN(name)       \n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    optimizer = optim.Adam(RPN.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # LOAD LAST CHECKPOINT IF choose_previous_model == True\n",
    "    choose_previous_model = cpm\n",
    "    previous_model_file_root = save_path\n",
    "    \n",
    "    if choose_previous_model == True:\n",
    "        # Choose which model to start from\n",
    "        previous_model = f'Last_RPN_{name}'#f\"model_weights_at_epoch_{int(epoch_number)}\"\n",
    "        checkpoint = torch.load(f\"{previous_model_file_root}/{previous_model}\")\n",
    "        RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        e = checkpoint['epoch'] + 1\n",
    "        loss = checkpoint['loss']\n",
    "        print(f\"Using previous model with name: \\n{previous_model}\\n\")\n",
    "        \n",
    "        loss_list = list(np.load(f'{save_path}/Loss_train_{name}.npy'))\n",
    "        loss_list_val = list(np.load(f'{save_path}/Loss_val_{name}.npy'))\n",
    "        \n",
    "        best_loss = np.min(loss_list_val)\n",
    "        choose_previous_model_factor = 2\n",
    "    else:\n",
    "        loss_list = []\n",
    "        loss_list_val = []\n",
    "        choose_previous_model_factor = 1\n",
    "        e = 0        \n",
    "\n",
    "    for e in range(e,e+n_epochs):\n",
    "        RPN.train()\n",
    "        print('Epoch '+str(e+1)+': ')\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        for img_batch, gt_bboxes_batch in dataloader_train:\n",
    "            img_batch = img_batch.to(device)\n",
    "            gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            loss,_,_,_ = RPN(img_batch, gt_bboxes_batch)\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        avg_loss = total_loss/n_train\n",
    "        print('Avg. train loss: ' + str(np.round(avg_loss,2)))\n",
    "\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        total_loss_val = 0\n",
    "        \n",
    "        \n",
    "        # val\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            torch.manual_seed(1)\n",
    "            np.random.seed(1)\n",
    "            \n",
    "            RPN.eval()\n",
    "            for img_batch, gt_bboxes_batch in dataloader_val:\n",
    "                img_batch = img_batch.to(device)\n",
    "                gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                loss_val,_,_,_ = RPN(img_batch, gt_bboxes_batch)\n",
    "\n",
    "                \n",
    "                total_loss_val += loss_val.item()\n",
    "\n",
    "            #print('val loss: ' + str(total_loss_val))\n",
    "\n",
    "\n",
    "            \n",
    "            avg_loss_val = total_loss_val/n_val\n",
    "            if e == 0:\n",
    "                best_loss = avg_loss_val\n",
    "\n",
    "            if avg_loss_val <= best_loss:\n",
    "                best_loss = avg_loss_val\n",
    "\n",
    "            print('Avg. val loss: ' + str(np.round(avg_loss_val,2)))\n",
    "\n",
    "            loss_list_val.append(avg_loss_val)\n",
    "\n",
    "        if e > 0 and save == True:                          \n",
    "            if avg_loss_val <= best_loss:\n",
    "                print('saving')\n",
    "                torch.save({'epoch': e,\n",
    "                                'model_state_dict': RPN.state_dict(),\n",
    "                                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                'loss': total_loss},\n",
    "                                f'{save_path}/Best_RPN_{name}') \n",
    "\n",
    "            if e == choose_previous_model_factor*n_epochs-1:\n",
    "                print('saving last model')\n",
    "                torch.save({'epoch': e,\n",
    "                                'model_state_dict': RPN.state_dict(),\n",
    "                                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                'loss': total_loss},\n",
    "                                f'{save_path}/Last_RPN_{name}') \n",
    "    \n",
    "    \n",
    "    if save == True:\n",
    "        np.save(f'{save_path}/Loss_train_{name}',loss_list)\n",
    "        np.save(f'{save_path}/Loss_val_{name}',loss_list_val)\n",
    "\n",
    "    return \n",
    "\n",
    "def train_model(name='example', n_epochs=50, dataset_size=40000, val_ratio=1/7., test_ratio=1/7., save=False, cpm=False):\n",
    "    save_path = f\"/scratch/s204219/RPN/{name}\"\n",
    "    if save == True:\n",
    "        if os.path.exists(save_path) and cpm == False:\n",
    "            choice = input(f\"{name} already exists. Do you want to overwrite it? (y/n)\")\n",
    "            if choice.lower() != 'y':\n",
    "                return\n",
    "            print('overwriting')\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "    \n",
    "    batch_size = 50\n",
    "\n",
    "    np.set_printoptions(precision=3)\n",
    "    \n",
    "    file_root = \"/scratch/s204219/augmentedData\"\n",
    "    file_list = np.arange(dsn,dsn+40000) \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomly select numbers from the array\n",
    "    file_list = np.random.choice(file_list, size=dataset_size, replace=False)\n",
    "    \n",
    "    dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Creating data indices for training and val splits:\n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    use_old_split = False\n",
    "    if dataset_size == 40000:\n",
    "        use_old_split = True\n",
    "    \n",
    "    train_indices, val_indices, _ = create_train_val_test_split(file_list=file_list, val_ratio=val_ratio, \\\n",
    "                                                                test_ratio=test_ratio, name=name, \\\n",
    "                                                                save_path=save_path, save=save, \\\n",
    "                                                                use_old_split=use_old_split)\n",
    "    ##############\n",
    "        \n",
    "#     train_indices = np.load('/scratch/s204219/RPN/big/Index_train_big.npy')\n",
    "#     val_indices   = np.load('/scratch/s204219/RPN/big/Index_val_big.npy')\n",
    "#     test_indices  = np.load('/scratch/s204219/RPN/big/Index_test_big.npy')\n",
    "    \n",
    "#     n_train = len(train_indices)\n",
    "#     n_train = int(np.round(n_train/5)) # if name == 'one'\n",
    "#     n_train = int(np.round((3*n_train)/5)) # if name == 'three'\n",
    "\n",
    "#     train_indices=train_indices[:n_train]\n",
    "    \n",
    "#     np.save(f'{save_path}/Index_train_{name}',train_indices)\n",
    "#     np.save(f'{save_path}/Index_val_{name}',val_indices)\n",
    "#     np.save(f'{save_path}/Index_test_{name}',test_indices)\n",
    "    \n",
    "    ##############\n",
    "    \n",
    "    \n",
    "    n_train = len(train_indices)\n",
    "    n_val = len(val_indices)\n",
    "    print('Number of training data: ' + str(n_train))\n",
    "    print('Number of validation data: ' + str(n_val))\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(np.argsort(train_indices)) # train_indices - dsn   if dataset_size = 40000 \n",
    "    valid_sampler = SubsetRandomSampler(np.argsort(val_indices)) # val_indices - dsn   if dataset_size = 40000 \n",
    "\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "    \n",
    "    #img_size = (256,256)\n",
    "    #out_size = (64,64)\n",
    "    #out_channels = 256\n",
    "\n",
    "    #RPN = RegionProposalNetwork_hyper(img_size, out_size, out_channels)\n",
    "    \n",
    "    RPN = init_RPN(name)       \n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    optimizer = optim.Adam(RPN.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # LOAD LAST CHECKPOINT IF choose_previous_model == True\n",
    "    \n",
    "    choose_previous_model = cpm\n",
    "    previous_model_file_root = save_path\n",
    "    if choose_previous_model == True:\n",
    "        # Choose which model to start from\n",
    "        previous_model = f'Last_RPN_{name}'#f\"model_weights_at_epoch_{int(epoch_number)}\"\n",
    "        checkpoint = torch.load(f\"{previous_model_file_root}/{previous_model}\")\n",
    "        RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        e = checkpoint['epoch'] + 1\n",
    "        loss = checkpoint['loss']\n",
    "        print(f\"Using previous model with name: \\n{previous_model}\\n\")\n",
    "    else:\n",
    "        e = 0 \n",
    "\n",
    "    \n",
    "\n",
    "    if choose_previous_model == True:\n",
    "        loss_list = list(np.load(f'{save_path}/Loss_train_{name}.npy'))\n",
    "        loss_list_val = list(np.load(f'{save_path}/Loss_val_{name}.npy'))\n",
    "        \n",
    "        best_loss = np.min(loss_list_val)\n",
    "        choose_previous_model_factor = 2\n",
    "        \n",
    "    \n",
    "    if choose_previous_model == False:\n",
    "        loss_list = []\n",
    "        loss_list_val = []\n",
    "        choose_previous_model_factor = 1\n",
    "\n",
    "    for e in range(e,e+n_epochs):\n",
    "        RPN.train()\n",
    "        print('Epoch '+str(e+1)+': ')\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        for img_batch, gt_bboxes_batch in dataloader_train:\n",
    "            img_batch = img_batch.to(device)\n",
    "            gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            loss,_,_,_ = RPN(img_batch, gt_bboxes_batch)\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        avg_loss = total_loss/n_train\n",
    "        print('Avg. train loss: ' + str(np.round(avg_loss,2)))\n",
    "\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        total_loss_val = 0\n",
    "        \n",
    "        # val\n",
    "        with torch.no_grad():\n",
    "            RPN.eval()\n",
    "            for img_batch, gt_bboxes_batch in dataloader_val:\n",
    "                img_batch = img_batch.to(device)\n",
    "                gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                loss_val,_,_,_ = RPN(img_batch, gt_bboxes_batch)\n",
    "\n",
    "                \n",
    "                total_loss_val += loss_val.item()\n",
    "\n",
    "            #print('val loss: ' + str(total_loss_val))\n",
    "\n",
    "\n",
    "            \n",
    "            avg_loss_val = total_loss_val/n_val\n",
    "            if e == 0:\n",
    "                best_loss = avg_loss_val\n",
    "\n",
    "            if avg_loss_val <= best_loss:\n",
    "                best_loss = avg_loss_val\n",
    "\n",
    "            print('Avg. val loss: ' + str(np.round(avg_loss_val,2)))\n",
    "\n",
    "            loss_list_val.append(avg_loss_val)\n",
    "\n",
    "        if e > 0 and save == True:                          \n",
    "            if avg_loss_val <= best_loss:\n",
    "                print('saving')\n",
    "                torch.save({'epoch': e,\n",
    "                                'model_state_dict': RPN.state_dict(),\n",
    "                                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                'loss': total_loss},\n",
    "                                f'{save_path}/Best_RPN_{name}') \n",
    "\n",
    "            if e == choose_previous_model_factor*n_epochs-1:\n",
    "                print('saving last model')\n",
    "                torch.save({'epoch': e,\n",
    "                                'model_state_dict': RPN.state_dict(),\n",
    "                                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                'loss': total_loss},\n",
    "                                f'{save_path}/Last_RPN_{name}') \n",
    "    \n",
    "    \n",
    "    if save == True:\n",
    "        np.save(f'{save_path}/Loss_train_{name}',loss_list)\n",
    "        np.save(f'{save_path}/Loss_val_{name}',loss_list_val)\n",
    "\n",
    "    return \n",
    "\n",
    "def test_model(name='temp',Best_or_Last='Best'): \n",
    "        \n",
    "    # Tests a given RPN model\n",
    "    \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    #previous_model_path = f\"/scratch/s204219/RPN/{name}\"\n",
    "    previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}'\n",
    "    batch_size = 50   \n",
    "    \n",
    "    file_root_test, _ = init_file_root_and_list(name=name)\n",
    "    file_list_test = np.load(f'{previous_model_path}/Index_test_{name}.npy')\n",
    "    \n",
    "    torch.manual_seed(seed=1)\n",
    "    np.random.seed(seed=1)\n",
    "    \n",
    "    dataset_test    = UXO_dataset(file_list=file_list_test, file_root=file_root_test)\n",
    "    dataloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)  \n",
    "    \n",
    "    n_batches = len(dataloader_test) \n",
    "    \n",
    "    RPN = init_RPN(name)\n",
    "    \n",
    "    checkpoint = torch.load(previous_model)\n",
    "    RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    total_loss_test = 0\n",
    "    k = 1\n",
    "    print('Beginning test')\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        torch.manual_seed(seed=1)\n",
    "        np.random.seed(seed=1)\n",
    "    \n",
    "        RPN.eval()\n",
    "        for img_batch, gt_bboxes_batch in dataloader_test:\n",
    "            img_batch = img_batch.to(device)\n",
    "            gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            loss_test,_,_,_ = RPN(img_batch, gt_bboxes_batch)\n",
    "\n",
    "            total_loss_test += loss_test.item()\n",
    "            \n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                print(f'Batch {k}/{n_batches}')\n",
    "            \n",
    "            k+=1\n",
    "            \n",
    "        \n",
    "    avg_loss_test = total_loss_test/len(dataset_test)\n",
    "    print('Avg. test loss: ' + str(avg_loss_test))\n",
    "    \n",
    "    np.save(f'{previous_model_path}/Loss_test_{Best_or_Last}_{name}',avg_loss_test)\n",
    "\n",
    "    \n",
    "    return \n",
    "\n",
    "def tune_model(name='temp',Best_or_Last='Best',train_or_val_or_test = 'val',conf_thresh_arr=[0.6,0.7],nms_thresh_arr=[0.1,0.2],save=False):\n",
    "    \n",
    "    # Tunes a given RPN model. Rather, it computes the confusion matrice\n",
    "    \n",
    "    # Confusion [conf_thresh,nms_thresh,2,2]\n",
    "    # Calculates the best values for confidence- and NMS thresholds from the validation dataset\n",
    "    \n",
    "    # previous_model_path = f\"/scratch/s204219/RPN/{name}\"\n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}' \n",
    "    \n",
    "    if save == True:\n",
    "        if train_or_val_or_test == 'val':\n",
    "            save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "            save_path_conf = f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}'\n",
    "            save_path_nms = f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}'\n",
    "        if train_or_val_or_test == 'test':\n",
    "            save_path = f'{previous_model_path}/Confusion_test_{Best_or_Last}_{name}'\n",
    "            save_path_conf = f'{previous_model_path}/conf_thresh_arr_test_{Best_or_Last}_{name}'\n",
    "            save_path_nms = f'{previous_model_path}/nms_thresh_arr_test_{Best_or_Last}_{name}'\n",
    "#         if os.path.exists(f'{save_path}.npy'):\n",
    "#             choice = input(f\"Confusion has already been calculated for {name}. Do you want to overwrite it? (y/n)\")\n",
    "#             if choice.lower() != 'y':\n",
    "#                 return\n",
    "\n",
    "    \n",
    "    file_root, _ = init_file_root_and_list(name=name)\n",
    "    file_list = np.load(f'{previous_model_path}/Index_{train_or_val_or_test}_{name}.npy')\n",
    "    \n",
    "    n = len(file_list)\n",
    "    batch_size = 50\n",
    "    dataset_test = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "    dataloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, num_workers=2)  \n",
    "    \n",
    "    n_batches = int(np.ceil(len(dataset_test)/batch_size))\n",
    "    \n",
    "    img_size = (256,256)\n",
    "    out_size = (64,64)\n",
    "    out_channels = 256\n",
    "    \n",
    "    height_scale_factor= img_size[0]/out_size[0]\n",
    "    width_scale_factor = img_size[1]/out_size[1]\n",
    "    \n",
    "    RPN = init_RPN(name)\n",
    "    \n",
    "    \n",
    "    checkpoint = torch.load(previous_model)\n",
    "    RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    n_anc_boxes_total = RPN.n_anc_boxes_total\n",
    "    pos_thresh = 0.3\n",
    "    \n",
    "    \n",
    "    \n",
    "    confusion = torch.zeros((len(conf_thresh_arr),len(nms_thresh_arr),2,2),device=device)\n",
    "    count_1 = 1\n",
    "    number_of_combinations = len(conf_thresh_arr)*len(nms_thresh_arr)\n",
    "    for j,nms_thresh in enumerate(nms_thresh_arr):\n",
    "        \n",
    "        for i,conf_thresh in enumerate(conf_thresh_arr):\n",
    "            \n",
    "            print(f'Beginning conf- and nms threshold combination number {count_1}/{number_of_combinations}')\n",
    "            tp, fp, fn, tn = 0, 0, 0, 0\n",
    "            count = 1\n",
    "            \n",
    "\n",
    "            for img_batch, gt_bboxes_batch in dataloader_test:\n",
    "\n",
    "\n",
    "                img_batch = img_batch.to(device)\n",
    "                gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "\n",
    "\n",
    "\n",
    "                gt_bboxes_proj = project_bboxes(gt_bboxes_batch, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "\n",
    "                proposals_final, conf_scores_final, feature_map = RPN.inference(img_batch,conf_thresh=conf_thresh,nms_thresh=nms_thresh)\n",
    "\n",
    "                tp_batch,fp_batch,fn_batch,tn_batch = \\\n",
    "                calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='sum')\n",
    "\n",
    "                tp+=tp_batch\n",
    "                fp+=fp_batch\n",
    "                fn+=fn_batch\n",
    "                tn+=tn_batch\n",
    "\n",
    "                if count % 50 == 0:\n",
    "                    print(f'Batch {count}/{n_batches} completed')\n",
    "\n",
    "                count += 1\n",
    "            \n",
    "            print('Done')\n",
    "            count_1+=1\n",
    "\n",
    "            # Averaging\n",
    "            tp, fp, fn, tn = tp/n, fp/n, fn/n, tn/n\n",
    "\n",
    "            confusion[i,j,:,:] = torch.tensor([[tp,fp],[fn,tn]],device=device)\n",
    "    \n",
    "    \n",
    "    confusion_np = confusion.detach().cpu().numpy()\n",
    "    \n",
    "    if save == True:\n",
    "        \n",
    "        conf_thresh_arr_np = np.array(conf_thresh_arr) \n",
    "        nms_thresh_arr_np  = np.array(nms_thresh_arr)\n",
    "\n",
    "        np.save(f'{save_path}',confusion_np)\n",
    "        np.save(f'{save_path_conf}',conf_thresh_arr_np)\n",
    "        np.save(f'{save_path_nms}',nms_thresh_arr_np)\n",
    "        \n",
    "        if train_or_val_or_test == 'val':\n",
    "            print('Done tuning')\n",
    "        if train_or_val_or_test == 'test':\n",
    "            print('Done testing')\n",
    "            \n",
    "            \n",
    "        \n",
    "        return\n",
    "    \n",
    "    if train_or_val_or_test == 'val':\n",
    "        print('Done tuning')\n",
    "    if train_or_val_or_test == 'test':\n",
    "        print('Done testing')\n",
    "    \n",
    "    return confusion_np\n",
    "\n",
    "def find_conf_and_nms_thresh(name='baseline', Best_or_Last='Best'):\n",
    "    \n",
    "    # Finds optimal confidence- and nms thresholds for a given RPN model\n",
    "    print_option = False\n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "\n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "\n",
    "    #fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    number_of_proposals = []\n",
    "    conf_thresh_optimal = []\n",
    "\n",
    "    for i, nms_thresh in enumerate(nms_thresh_arr):\n",
    "\n",
    "        tp = confusion[:,i,0,0]\n",
    "        #axes[0].plot(conf_thresh_arr,tp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "        fp = confusion[:,i,0,1]\n",
    "\n",
    "        number_of_proposals.append(tp+fp)\n",
    "\n",
    "        fn = confusion[:,i,1,0]\n",
    "        #axes[1].plot(conf_thresh_arr,fn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "\n",
    "        tp_mask = np.logical_and(tp>=0.75,tp<1.0)\n",
    "        fn_mask = fn<=0.25\n",
    "        mask = np.logical_and(tp_mask,fn_mask)\n",
    "        #print(conf_thresh_arr[mask])\n",
    "        possible_conf_thresh = conf_thresh_arr[mask]\n",
    "        if len(possible_conf_thresh) != 0:\n",
    "            best_conf_thresh = possible_conf_thresh[-1]\n",
    "            #print(best_conf_thresh)\n",
    "\n",
    "            best_conf_thresh_idx = np.where(best_conf_thresh == conf_thresh_arr)[0][0]\n",
    "            if print_option == True:\n",
    "                print(best_conf_thresh)\n",
    "            conf_thresh_optimal.append(best_conf_thresh)\n",
    "\n",
    "            number_of_proposals[i] = number_of_proposals[i][best_conf_thresh_idx]\n",
    "\n",
    "        if len(possible_conf_thresh) == 0:\n",
    "            number_of_proposals[i] = float('inf')\n",
    "            conf_thresh_optimal.append(float('inf'))\n",
    "        if print_option == True:\n",
    "            print(number_of_proposals[i])\n",
    "            print('---------------')\n",
    "\n",
    "    best_nms_thresh_idx = np.argmin(number_of_proposals)\n",
    "    best_nms_thresh = nms_thresh_arr[best_nms_thresh_idx]\n",
    "    best_conf_thresh = conf_thresh_optimal[best_nms_thresh_idx]\n",
    "\n",
    "    if print_option == True:\n",
    "        print('Optimal conf thresh: ' + str(np.round(best_conf_thresh,2)))\n",
    "        print('Optimal nms thresh: ' + str(np.round(best_nms_thresh,2)))\n",
    "    \n",
    "    return best_conf_thresh, best_nms_thresh\n",
    "\n",
    "def test_model_confusion(name='temp',Best_or_Last='Best',conf_thresh_arr=[0.6,0.7],nms_thresh_arr=[0.1,0.2]):\n",
    "    \n",
    "    save=True\n",
    "    train_or_val_or_test='test'\n",
    "    \n",
    "    confusion = tune_model(name=f'{name}',Best_or_Last=f'{Best_or_Last}',\\\n",
    "                           train_or_val_or_test=f'{train_or_val_or_test}',\\\n",
    "                           conf_thresh_arr=conf_thresh_arr,\\\n",
    "                           nms_thresh_arr=nms_thresh_arr,save=save)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # confusion = confusion[0,0,:,:]\n",
    "    \n",
    "    return confusion #tp, fp, fn, tn\n",
    "\n",
    "def print_results(names=['baseline','hyper']):\n",
    "    \n",
    "    Best_or_Last = 'Best'\n",
    "    \n",
    "    test_loss_all = []\n",
    "    \n",
    "    best_conf_thresh = []\n",
    "    best_nms_thresh  = []\n",
    "    \n",
    "    no_prop_all = []\n",
    "    recall_all = []\n",
    "    precision_all = []\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "        save_path = f'{previous_model_path}/Confusion_test_{Best_or_Last}_{name}'\n",
    "\n",
    "        test_loss = np.load(f'{previous_model_path}/Loss_test_Best_{name}.npy')\n",
    "        \n",
    "        confusion = np.load(f'{save_path}.npy')\n",
    "        conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_test_{Best_or_Last}_{name}.npy')\n",
    "        nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_test_{Best_or_Last}_{name}.npy')\n",
    "        \n",
    "        \n",
    "        conf, nms = find_conf_and_nms_thresh(name=f'{name}',Best_or_Last='Best')\n",
    "                \n",
    "        i = np.where(nms == nms_thresh_arr)[0][0]\n",
    "        j = np.where(conf == conf_thresh_arr)[0][0]\n",
    "    \n",
    "        tp = confusion[j,i,0,0]\n",
    "        fp = confusion[j,i,0,1]\n",
    "        fn = confusion[j,i,1,0]\n",
    "        tn = confusion[j,i,1,1]\n",
    "        \n",
    "        no_prop   = tp+fp\n",
    "        recall    = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        \n",
    "        test_loss_all.append(test_loss)\n",
    "    \n",
    "        best_conf_thresh.append(conf)\n",
    "        best_nms_thresh.append(nms)\n",
    "\n",
    "        no_prop_all.append(no_prop)\n",
    "        recall_all.append(recall)\n",
    "        precision_all.append(precision)\n",
    "    \n",
    "    mat = np.zeros((6,len(names)))\n",
    "    mat[0,:] = np.array(test_loss_all)\n",
    "    mat[1,:] = np.array(best_conf_thresh)\n",
    "    mat[2,:] = np.array(best_nms_thresh)\n",
    "    mat[3,:] = np.array(no_prop_all)\n",
    "    mat[4,:] = np.array(recall_all)\n",
    "    mat[5,:] = np.array(precision_all)\n",
    "    \n",
    "    \n",
    "    print(np.round(mat,2))\n",
    "    \n",
    "    return mat\n",
    "        \n",
    "\n",
    "# PLOTTING\n",
    "\n",
    "def plot_pos_neg_ABs(): \n",
    "    # %% PlOT POSITIVE AND NEGATIVE AB'S \n",
    "    img_size = (256,256)\n",
    "    out_size = (64,64)\n",
    "    out_channels = 256\n",
    "\n",
    "    height_scale_factor= img_size[0]/out_size[0]\n",
    "    width_scale_factor = img_size[1]/out_size[1]\n",
    "\n",
    "\n",
    "    file_root = \"/scratch/s204219/augmentedData\"\n",
    "    file_list = np.arange(dsn,dsn+400)\n",
    "\n",
    "    dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "    batch_size = 16\n",
    "\n",
    "    # ONLY WORKS IF num_workers = 0 \n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, num_workers=0) \n",
    "\n",
    "    img_batch, gt_bboxes_batch = next(iter(dataloader))\n",
    "\n",
    "\n",
    "    img_data_all = img_batch[11:13].to(device)\n",
    "    gt_bboxes_all = gt_bboxes_batch[11:13].to(device)\n",
    "\n",
    "    out_h,out_w = 64,64\n",
    "\n",
    "    anc_pts_x, anc_pts_y = gen_anc_centers(out_size=(out_h, out_w))\n",
    "    anc_scales = [8,10]#[2, 4, 6]\n",
    "    anc_ratios = [1]\n",
    "    n_anc_boxes = len(anc_scales) * len(anc_ratios) # number of anchor boxes for each anchor point\n",
    "\n",
    "    anc_base = gen_anc_base(anc_pts_x, anc_pts_y, anc_scales, anc_ratios, (out_h, out_w))\n",
    "\n",
    "    anc_boxes_all = anc_base.repeat(img_data_all.size(dim=0), 1, 1, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    pos_thresh = 0.7\n",
    "    neg_thresh = 0.3\n",
    "\n",
    "    # project gt bboxes onto the feature map\n",
    "    gt_bboxes_proj = project_bboxes(gt_bboxes_all, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "    positive_anc_ind, negative_anc_ind, GT_conf_scores, \\\n",
    "    GT_offsets, positive_anc_coords, \\\n",
    "    negative_anc_coords, positive_anc_ind_sep = get_req_anchors(anc_boxes_all, gt_bboxes_proj, pos_thresh, neg_thresh)\n",
    "\n",
    "    # project anchor coords to the image space\n",
    "    pos_anc_proj = project_bboxes(positive_anc_coords, width_scale_factor, height_scale_factor, mode='a2p')\n",
    "    neg_anc_proj = project_bboxes(negative_anc_coords, width_scale_factor, height_scale_factor, mode='a2p')\n",
    "\n",
    "    # grab +ve and -ve anchors for each image separately\n",
    "\n",
    "    anc_idx_1 = torch.where(positive_anc_ind_sep == 0)[0]\n",
    "    anc_idx_2 = torch.where(positive_anc_ind_sep == 1)[0]\n",
    "\n",
    "    pos_anc_1 = pos_anc_proj[anc_idx_1]\n",
    "    pos_anc_2 = pos_anc_proj[anc_idx_2]\n",
    "\n",
    "    neg_anc_1 = neg_anc_proj[anc_idx_1]\n",
    "    neg_anc_2 = neg_anc_proj[anc_idx_2]\n",
    "\n",
    "    nrows, ncols = (1, 2)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(16, 8))\n",
    "\n",
    "    fig, axes = display_img(img_data_all.detach().cpu(), fig, axes)\n",
    "\n",
    "    # plot groundtruth bboxes\n",
    "    fig, _ = display_bbox(gt_bboxes_all[0].detach().cpu(), fig, axes[0])\n",
    "    fig, _ = display_bbox(gt_bboxes_all[1].detach().cpu(), fig, axes[1])\n",
    "\n",
    "    # plot positive anchor boxes\n",
    "    fig, _ = display_bbox(pos_anc_1.detach().cpu(), fig, axes[0], color='g')\n",
    "    fig, _ = display_bbox(pos_anc_2.detach().cpu(), fig, axes[1], color='g')\n",
    "\n",
    "    # plot negative anchor boxes\n",
    "    fig, _ = display_bbox(neg_anc_1.detach().cpu(), fig, axes[0], color='r')\n",
    "    fig, _ = display_bbox(neg_anc_2.detach().cpu(), fig, axes[1], color='r')\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_proposals(name='temp',Best_or_Last='Best',train_or_val_or_test='test',conf_thresh=0.6,nms_thresh=0.1,idx=0,number=4,no_proposals=10):\n",
    "    \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}'    \n",
    "    \n",
    "    index = np.load(f'{previous_model_path}/Index_{train_or_val_or_test}_{name}.npy')\n",
    "    \n",
    "    #file_root  = \"/scratch/s204219/augmentedData\"   \n",
    "    file_root,_ = init_file_root_and_list(name=name)\n",
    "    \n",
    "    file_list  = index[idx:idx+number*2]  \n",
    "    # np.array([index[4],index[8]])\n",
    "    \n",
    "    dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "    \n",
    "    RPN = init_RPN(name)\n",
    "    \n",
    "    width_scale_factor  = RPN.width_scale_factor\n",
    "    height_scale_factor = RPN.height_scale_factor\n",
    "    \n",
    "    checkpoint = torch.load(previous_model)\n",
    "    RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    n_anc_boxes_total = RPN.n_anc_boxes_total\n",
    "    \n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # e = checkpoint['epoch']\n",
    "    # loss = checkpoint['loss']\n",
    "    \n",
    "     \n",
    "    \n",
    "    img_batch,bb_batch = dataset[:]\n",
    "    batch_size = len(bb_batch)\n",
    "\n",
    "    gt_bboxes_proj = project_bboxes(bb_batch, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "    \n",
    "    \n",
    "    proposals_final, conf_scores_final, feature_map = RPN.inference(img_batch.to(device),conf_thresh=conf_thresh,nms_thresh=nms_thresh)\n",
    "    for j in range(number):\n",
    "        proposals_final[j*2] = proposals_final[j*2][:no_proposals,:]\n",
    "        proposals_final[j*2+1] = proposals_final[j*2+1][:no_proposals,:]\n",
    "        \n",
    "        \n",
    "    \n",
    "    pos_thresh = 0.3\n",
    "    tp,fp,fn,tn = calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='list')\n",
    "    # print('Image 1 tp:' + str(tp[i*2].detach().cpu().numpy()) + '| Image 2 tp:' + str(tp[i*2+1].detach().cpu().numpy()))    \n",
    "    \n",
    "    for i in range(number):\n",
    "                \n",
    "        if proposals_final[i*2].shape == torch.Size([0, 4]):\n",
    "            proposals_final[i*2] = torch.tensor([[0,0,0,0]],device=device)\n",
    "        if proposals_final[i*2+1].shape == torch.Size([0, 4]):\n",
    "            proposals_final[i*2+1] = torch.tensor([[0,0,0,0]],device=device)\n",
    "            \n",
    "        proposals_proj = project_bboxes(proposals_final[i*2], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu(), \\\n",
    "                       project_bboxes(proposals_final[i*2+1], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu()\n",
    "        nrows, ncols = (1, 2)\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(10, 5))\n",
    "\n",
    "        fig, axes = display_img(img_batch[i*2:i*2+2], fig, axes)\n",
    "\n",
    "        # plot proposals\n",
    "        \n",
    "        fig, _ = display_bbox(proposals_proj[0][:no_proposals,:], fig, axes[0])\n",
    "        fig, _ = display_bbox(proposals_proj[1][:no_proposals,:], fig, axes[1])\n",
    "        \n",
    "        #fig, _ = display_bbox(proposals_proj[0], fig, axes[0])\n",
    "        #fig, _ = display_bbox(proposals_proj[1], fig, axes[1])\n",
    "        \n",
    "        # add titles to the figures\n",
    "        # f'tp={tp[j]}, ' + f'fp={fp[j]}'\n",
    "        axes[0].set_title(f'tp={tp[i*2]}, ' + f'fp={fp[i*2]}')#, ' + f'fn={fn[i*2]}, ' + f'tn={tn[i*2]}')\n",
    "        axes[1].set_title(f'tp={tp[i*2+1]}, ' + f'fp={fp[i*2+1]}')#, ' + f'fn={fn[i*2+1]}, ' + f'tn={tn[i*2+1]}' )\n",
    "        \n",
    "        plt.setp(axes, xticks=[], yticks=[])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return \n",
    "\n",
    "def plot_train_val_test_proposals(name='temp',Best_or_Last='Best',conf_thresh=0.6,nms_thresh=0.2,idx=[0,0,0],number=2,no_proposals=10):\n",
    "       \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    #previous_model_path = f\"/scratch/s204219/RPN/{name}\"\n",
    "    previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}'    \n",
    "    \n",
    "    index_train = np.load(f'{previous_model_path}/Index_train_{name}.npy')\n",
    "    index_val   = np.load(f'{previous_model_path}/Index_val_{name}.npy')\n",
    "    index_test  = np.load(f'{previous_model_path}/Index_test_{name}.npy')\n",
    " \n",
    "    file_root,_ = init_file_root_and_list(name=name)\n",
    "    \n",
    "    file_list_train  = index_train[idx[0]:idx[0]+number] \n",
    "    file_list_val    = index_val[idx[1]:idx[1]+number] \n",
    "    file_list_test   = index_test[idx[2]:idx[2]+number] \n",
    "\n",
    "    dataset_train = UXO_dataset(file_list=file_list_train, file_root=file_root)\n",
    "    dataset_val   = UXO_dataset(file_list=file_list_val, file_root=file_root)\n",
    "    dataset_test  = UXO_dataset(file_list=file_list_test, file_root=file_root)\n",
    "\n",
    "    RPN = init_RPN(name)\n",
    "\n",
    "    checkpoint = torch.load(previous_model)\n",
    "    RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    n_anc_boxes_total   = RPN.n_anc_boxes_total\n",
    "    height_scale_factor = RPN.height_scale_factor\n",
    "    width_scale_factor  = RPN.width_scale_factor\n",
    "\n",
    "    img_height = RPN.img_height\n",
    "    img_width  = RPN.img_width\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(number,3, figsize=(8, 8))\n",
    "\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            dataset = dataset_train\n",
    "        if i == 1:\n",
    "            dataset = dataset_val\n",
    "        if i == 2:\n",
    "            dataset = dataset_test\n",
    "\n",
    "        img_batch,bb_batch = dataset[:] # [:] is very important\n",
    "\n",
    "        gt_bboxes_proj = project_bboxes(bb_batch, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "\n",
    "        proposals_final, conf_scores_final, feature_map = RPN.inference(img_batch.to(device),conf_thresh=conf_thresh,nms_thresh=nms_thresh)\n",
    "        for j in range(number):\n",
    "            proposals_final[j] = proposals_final[j][:no_proposals,:]\n",
    "        \n",
    "        pos_thresh = 0.3    \n",
    "        tp,fp,fn,tn = calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='list')\n",
    "\n",
    "        for j in range(number):\n",
    "            if proposals_final[j].shape == torch.Size([0, 4]):\n",
    "                proposals_final[j] = torch.tensor([[0,0,0,0]],device=device)\n",
    "            \n",
    "            \n",
    "            proposals_proj = project_bboxes(proposals_final[j], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu()\n",
    "\n",
    "            img = img_batch[j,:,:,:].permute(1, 2, 0).numpy()\n",
    "            axes[j,i].imshow(img.astype('uint8'))\n",
    "\n",
    "            # plot proposals\n",
    "            fig, _ = display_bbox(proposals_proj[:no_proposals,:], fig, axes[j,i])\n",
    "            fig, _ = display_bbox(bb_batch[j], fig, axes[j,i], color='r')\n",
    "\n",
    "            # add titles to the figures\n",
    "            if j == 0 and i == 0:\n",
    "                axes[j,i].set_title('Train\\n' +f'tp={tp[j]}, ' + f'fp={fp[j]}')\n",
    "            if j == 0 and i == 1:\n",
    "                axes[j,i].set_title('Validation\\n' +f'tp={tp[j]}, ' + f'fp={fp[j]}')\n",
    "            if j == 0 and i == 2:\n",
    "                axes[j,i].set_title('Test\\n' +f'tp={tp[j]}, ' + f'fp={fp[j]}')\n",
    "            if j > 0:\n",
    "                axes[j,i].set_title(f'tp={tp[j]}, ' + f'fp={fp[j]}')\n",
    "\n",
    "    plt.setp(axes, xticks=[], yticks=[])\n",
    "    plt.suptitle(f'Model: {name}\\n{no_proposals} best proposals',fontsize = 20,y=1.05)\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_train_val_loss(name='overfitted',n_epochs='all', move=0):\n",
    "    \n",
    "    #location = -1, 5\n",
    "    \n",
    "       \n",
    "    \n",
    "    path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    # path = f\"/scratch/s204219/RPN/{name}\"\n",
    "    train_loss = np.load(f'{path}/Loss_train_{name}.npy') #\n",
    "    val_loss   = np.load(f'{path}/Loss_val_{name}.npy')   #\n",
    "    \n",
    "    \n",
    "    if n_epochs == 'all' or n_epochs > len(train_loss):\n",
    "        n_epochs = len(train_loss)\n",
    "    \n",
    "    train_loss = train_loss[:n_epochs]\n",
    "    val_loss   = val_loss[:n_epochs]\n",
    "    \n",
    "    if np.max(train_loss) >= np.max(val_loss):\n",
    "        loss = train_loss\n",
    "    else:\n",
    "        loss = val_loss\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    min_loss_epoch = np.argmin(loss) + 1 # add 1 to make it 1-indexed\n",
    "    min_loss = loss[min_loss_epoch-1]\n",
    "    \n",
    "    max_loss = np.max(loss)\n",
    "    \n",
    "    location = [-3,2*(max_loss-min_loss)/5]\n",
    "    \n",
    "    if min_loss_epoch + location[0] <= 0.5:\n",
    "        location[0]+=2\n",
    "    \n",
    "    if min_loss_epoch + location[0] >= n_epochs-20:\n",
    "        location[0]-=n_epochs/8\n",
    "        \n",
    "    location[0]+=move\n",
    "    \n",
    "    epochs = range(1,n_epochs+1) #\n",
    "    \n",
    "    plt.figure(figsize=(8,3))\n",
    "    \n",
    "    plt.plot(epochs, train_loss, label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, label = 'Validation loss')\n",
    "    \n",
    "    min_val_loss_epoch = np.argmin(val_loss) + 1 # add 1 to make it 1-indexed\n",
    "    min_val_loss = np.min(val_loss)\n",
    "    \n",
    "    plt.plot(min_val_loss_epoch, min_val_loss, 'ro',label = 'Min. val. loss')#, label = 'Minimum validation loss')\n",
    "    # 'ro' specifies the red dot marker\n",
    "    \n",
    "    arrow_props = dict(facecolor='red', edgecolor='red',\n",
    "                       arrowstyle=\"-|>, head_width=0.5, head_length=1.5\")\n",
    "    \n",
    "    \n",
    "    plt.annotate(f'Epoch: {min_val_loss_epoch}\\nLoss: {min_val_loss:.2f}', \n",
    "                 xy=(min_val_loss_epoch, min_val_loss), xycoords='data',\n",
    "                 xytext=(min_val_loss_epoch+location[0], min_val_loss+location[1]), textcoords='data',\n",
    "                 arrowprops=arrow_props,\n",
    "                 bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"red\", lw=1.5, alpha=0.9))\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')#'upper left')\n",
    "    \n",
    "    if n_epochs == 20:\n",
    "        plt.xticks(range(0,n_epochs+1,2))\n",
    "    elif n_epochs == 100:\n",
    "        plt.xticks(range(0,n_epochs+1,10))\n",
    "    \n",
    "    #plt.yticks([10,20,40,60,80,100])\n",
    "    plt.ylim(0,150)\n",
    "    \n",
    "    \n",
    "    plt.title(f'Model: {name}\\nTrain- and validation loss')\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_confusion(name='temp', Best_or_Last='Best', nms_thresh='all'):\n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "    \n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "    \n",
    "    \n",
    "    if nms_thresh != 'all':\n",
    "        i = np.argmin(abs(nms_thresh_arr-nms_thresh))\n",
    "        nms_thresh = nms_thresh_arr[i]\n",
    "        \n",
    "        tp = confusion[:,i,0,0]\n",
    "        axes[0,0].plot(conf_thresh_arr,tp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}',color=f'C{i}')\n",
    "        \n",
    "        tn = confusion[:,i,1,1]\n",
    "        axes[1,1].plot(conf_thresh_arr,tn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}',color=f'C{i}')\n",
    "        \n",
    "        fn = confusion[:,i,1,0]\n",
    "        axes[1,0].plot(conf_thresh_arr,fn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}',color=f'C{i}')\n",
    "        \n",
    "        fp = confusion[:,i,0,1]\n",
    "        axes[0,1].plot(conf_thresh_arr,fp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}',color=f'C{i}')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i, nms_thresh in enumerate(nms_thresh_arr):\n",
    "\n",
    "            tp = confusion[:,i,0,0]\n",
    "            axes[0,0].plot(conf_thresh_arr,tp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "\n",
    "            tn = confusion[:,i,1,1]\n",
    "            axes[1,1].plot(conf_thresh_arr,tn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "\n",
    "            fn = confusion[:,i,1,0]\n",
    "            axes[1,0].plot(conf_thresh_arr,fn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "\n",
    "            fp = confusion[:,i,0,1]\n",
    "            axes[0,1].plot(conf_thresh_arr,fp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "        \n",
    "        \n",
    "    axes[0,0].legend(loc='best')\n",
    "    axes[0,0].set_xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    axes[0,0].set_ylabel('TP',fontsize = 15)\n",
    "    axes[0,0].plot(conf_thresh_arr,[0.75]*len(conf_thresh_arr),color='black')\n",
    "    \n",
    "    #axes[1,1].legend(loc='best')\n",
    "    axes[1,1].set_xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    axes[1,1].set_ylabel('TN',fontsize = 15)\n",
    "\n",
    "    #axes[1,0].legend(loc='best')\n",
    "    axes[1,0].set_xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    axes[1,0].set_ylabel('FN',fontsize = 15)\n",
    "    axes[1,0].plot(conf_thresh_arr,[0.25]*len(conf_thresh_arr),color='black')\n",
    "\n",
    "    #axes[0,1].legend(loc='best')\n",
    "    axes[0,1].set_xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    axes[0,1].set_ylabel('FP',fontsize = 15)\n",
    "#     plt.title(name)\n",
    "    \n",
    "    #axes[0,0].xticks(conf_thresh_arr)\n",
    "    #axes[0,0].set_title('True positives')\n",
    "    #axes[1,1].set_title('True negatives')\n",
    "    #axes[1,0].set_title('False negatives')\n",
    "    #axes[0,1].set_title('False positives')\n",
    "    plt.suptitle(f'Model: {name}\\nAverage confusion',fontsize = 20)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.15, hspace=0.25)\n",
    "    #fig.supxlabel('Confidence threshold')\n",
    "    xticks_arr = np.arange(0.0,1.1,0.1) \n",
    "    plt.setp(axes, xticks=xticks_arr)\n",
    "    \n",
    "    plt.imshow\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_tp_and_fn(name='temp', Best_or_Last='Best'):\n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "    \n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    \n",
    "    \n",
    "    conf, nms = find_conf_and_nms_thresh(name=f'{name}', Best_or_Last=f'{Best_or_Last}')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    \n",
    "    for i, nms_thresh in enumerate(nms_thresh_arr):\n",
    "        \n",
    "        \n",
    "        \n",
    "        tp = confusion[:,i,0,0]\n",
    "        axes[0].plot(conf_thresh_arr,tp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "        \n",
    "        fn = confusion[:,i,1,0]\n",
    "        axes[1].plot(conf_thresh_arr,fn,marker='.')#,label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "    \n",
    "    i = np.where(nms == nms_thresh_arr)[0][0]\n",
    "    j = np.where(conf == conf_thresh_arr)[0][0]\n",
    "    \n",
    "    tp = confusion[j,i,0,0]\n",
    "    axes[0].scatter(conf,tp,marker='*',label = 'Optimal model',color='magenta',s=100,zorder=10)\n",
    "\n",
    "    fp = confusion[j,i,0,1]\n",
    "    \n",
    "    fn = confusion[j,i,1,0]\n",
    "    axes[1].scatter(conf,fn,marker='*',label = 'Conf. thresh '+r'$\\alpha = $'+str(np.round(conf,2))+\\\n",
    "                    '\\n'+'NMS thresh '+r'$\\beta = $'+str(np.round(nms,2))+'\\n'+\\\n",
    "                    'No. proposals '+r'$P =$'+str(np.round(tp+fp,2)) +\\\n",
    "                    '\\n'+r'$TP =$'+str(np.round(tp,2)) + '\\n' \\\n",
    "                    r'$FN =$' + str(np.round(fn,2)),\\\n",
    "                    color='magenta',s=100,zorder=10)    \n",
    "    \n",
    "        \n",
    "    axes[0].legend(loc='best')\n",
    "    axes[0].set_xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    axes[0].set_ylabel('TP',fontsize = 15)\n",
    "    axes[0].plot(conf_thresh_arr,[0.75]*len(conf_thresh_arr),color='black')\n",
    "    axes[0].plot(conf_thresh_arr,[1.0]*len(conf_thresh_arr),color='black')\n",
    "    \n",
    "    rect0 = patches.Rectangle((0.0, 0.75), 1.0, 0.25, alpha=0.5, facecolor='darkgray')\n",
    "\n",
    "    # Add the rectangle patch to the axis\n",
    "    axes[0].add_patch(rect0)\n",
    "    \n",
    "    \n",
    "    axes[1].legend(loc='best')\n",
    "    axes[1].set_xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    axes[1].set_ylabel('FN',fontsize = 15)\n",
    "    axes[1].plot(conf_thresh_arr,[0.25]*len(conf_thresh_arr),color='black')\n",
    "    axes[1].plot(conf_thresh_arr,[0.0]*len(conf_thresh_arr),color='black')\n",
    "    \n",
    "    rect1 = patches.Rectangle((0.0, 0.0), 1.0, 0.25, alpha=0.5, facecolor='darkgray')\n",
    "\n",
    "    # Add the rectangle patch to the axis\n",
    "    axes[1].add_patch(rect1)\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    \n",
    "    plt.suptitle(f'Model: {name}\\nAverage TP and FN for validation data',fontsize = 20)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.15, hspace=2)\n",
    "    #fig.supxlabel('Confidence threshold')\n",
    "    xticks_arr = np.arange(0.0,1.1,0.1) \n",
    "    plt.setp(axes, xticks=xticks_arr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.imshow\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_fn(name='temp', Best_or_Last='Best', nms_thresh='all'):\n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "    \n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "    \n",
    "    \n",
    "    if nms_thresh != 'all':\n",
    "        i = np.argmin(abs(nms_thresh_arr-nms_thresh))\n",
    "        nms_thresh = nms_thresh_arr[i]\n",
    "        \n",
    "        \n",
    "        fn = confusion[:,i,1,0]\n",
    "        plt.plot(conf_thresh_arr,fn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}',color=f'C{i}')\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i, nms_thresh in enumerate(nms_thresh_arr):\n",
    "\n",
    "            fn = confusion[:,i,1,0]\n",
    "            plt.plot(conf_thresh_arr,fn,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    plt.ylabel('FN',fontsize = 15)\n",
    "    plt.plot(conf_thresh_arr,[0.25]*len(conf_thresh_arr),color='black')\n",
    "    plt.plot(conf_thresh_arr,[0.0]*len(conf_thresh_arr),color='black')\n",
    "\n",
    "    plt.title(f'Model: {name}\\nAverage FN',fontsize = 20)\n",
    "    \n",
    "    rect = patches.Rectangle((0.0, 0.0), 1.0, 0.25, alpha=0.5, facecolor='darkgray')\n",
    "\n",
    "    # Add the rectangle patch to the axis\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    #plt.xlim((0.0, 1.0))  \n",
    "    \n",
    "    xticks_arr = np.arange(0.0,1.1,0.1) \n",
    "    plt.xticks(xticks_arr)\n",
    "    \n",
    "    plt.imshow\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_tp(name='temp', Best_or_Last='Best', nms_thresh='all'):\n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "    \n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "    \n",
    "    \n",
    "    if nms_thresh != 'all':\n",
    "        i = np.argmin(abs(nms_thresh_arr-nms_thresh))\n",
    "        nms_thresh = nms_thresh_arr[i]\n",
    "        \n",
    "        \n",
    "        tp = confusion[:,i,0,0]\n",
    "        plt.plot(conf_thresh_arr,tp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}',color=f'C{i}')\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i, nms_thresh in enumerate(nms_thresh_arr):\n",
    "\n",
    "            tp = confusion[:,i,0,0]\n",
    "            plt.plot(conf_thresh_arr,tp,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Confidence threshold ' + r'$ (\\alpha)$',fontsize = 13)\n",
    "    plt.ylabel('TP',fontsize = 15)\n",
    "    plt.plot(conf_thresh_arr,[0.75]*len(conf_thresh_arr),color='black')\n",
    "    plt.plot(conf_thresh_arr,[1.0]*len(conf_thresh_arr),color='black')\n",
    "    \n",
    "    rect = patches.Rectangle((0.0, 0.75), 1.0, 0.25, alpha=0.5, facecolor='darkgray')\n",
    "\n",
    "    # Add the rectangle patch to the axis\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    plt.title(f'Model: {name}\\nAverage TP',fontsize = 20)\n",
    "    \n",
    "    #plt.xlim((0.0, 1.0))  \n",
    "    \n",
    "    xticks_arr = np.arange(0.0,1.1,0.1) \n",
    "    plt.xticks(xticks_arr)\n",
    "    \n",
    "    plt.imshow\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_ROC(name='temp',Best_or_Last='Best'):\n",
    "    \n",
    "    \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "    \n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    plt.figure()\n",
    "    for i,nms_thresh in enumerate(nms_thresh_arr):\n",
    "    \n",
    "        tp = confusion[:,i,0,0]\n",
    "        tn = confusion[:,i,1,1]\n",
    "        fn = confusion[:,i,1,0]\n",
    "        fp = confusion[:,i,0,1]\n",
    "\n",
    "        tpr = tp/(tp+fn)\n",
    "\n",
    "        fpr = fp/(fp+tn)\n",
    "        \n",
    "        plt.plot(fpr,tpr,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('fpr')\n",
    "    plt.ylabel('tpr')\n",
    "    plt.title(f'Model: {name}\\nReceiver operating characteristic (ROC) curve')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_precision_recall(name='temp',Best_or_Last='Best'):\n",
    "    \n",
    "    \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    save_path = f'{previous_model_path}/Confusion_{Best_or_Last}_{name}'\n",
    "    \n",
    "    confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "    conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_{Best_or_Last}_{name}.npy')\n",
    "    \n",
    "    F1 = []\n",
    "    \n",
    "    for i,nms_thresh in enumerate(nms_thresh_arr):\n",
    "    \n",
    "        tp = confusion[:,i,0,0]\n",
    "        tn = confusion[:,i,1,1]\n",
    "        fn = confusion[:,i,1,0]\n",
    "        fp = confusion[:,i,0,1]\n",
    "        \n",
    "        # Precision\n",
    "        pre = tp/(tp+fp)\n",
    "        \n",
    "        # Recall\n",
    "        rec = tp/(tp+fn)\n",
    "        \n",
    "        F1.append(2*tp/(2*tp + fp + fn)) # 1 /( 1/rec + 1/pre )\n",
    "        \n",
    "        plt.plot(rec,pre,marker='.',label = f'NMS thresh = {np.round(nms_thresh,2)}')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Recall  '+ r'$\\dfrac{tp}{tp+fn}$')\n",
    "    plt.ylabel('Precision  '+ r'$\\dfrac{tp}{tp+fp}$')\n",
    "    plt.title(f'Model: {name}\\nPrecision-Recall curve')\n",
    "    plt.show()\n",
    "    \n",
    "    return F1\n",
    "\n",
    "def plot_recall_vs_number_of_propsals(name='temp',nms_thresh='all'):\n",
    "    \n",
    "    Best_or_Last='Best'\n",
    "    \n",
    "    if isinstance(name,str):\n",
    "        one_model_only = True\n",
    "        names = [name]\n",
    "        nms_thresh = [nms_thresh]\n",
    "    \n",
    "    if isinstance(name,list):\n",
    "        one_model_only = False\n",
    "        names = name\n",
    "    \n",
    "    nms_thresh = nms_thresh.copy()\n",
    "    \n",
    "    best_conf_thresh = []\n",
    "    best_nms_thresh  = []\n",
    "    nms_thresh_was_best = []\n",
    "    \n",
    "    for j,name in enumerate(names):\n",
    "        conf, nms = find_conf_and_nms_thresh(name=f'{name}',Best_or_Last=f'{Best_or_Last}')\n",
    "        best_conf_thresh.append(conf)\n",
    "        best_nms_thresh.append(nms)\n",
    "    \n",
    "        if nms_thresh[j] == 'best':\n",
    "            nms_thresh[j] = best_nms_thresh[j]\n",
    "            nms_thresh_was_best.append(True)\n",
    "        else:\n",
    "            nms_thresh_was_best.append(False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,3))\n",
    "    max_no_prop = -1\n",
    "    for j,name in enumerate(names):\n",
    "        previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "        save_path = f'{previous_model_path}/Confusion_test_{Best_or_Last}_{name}'\n",
    "\n",
    "        confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "        conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_test_{Best_or_Last}_{name}.npy')\n",
    "        nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_test_{Best_or_Last}_{name}.npy')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if nms_thresh[j] != 'all':\n",
    "            i = np.argmin(abs(nms_thresh_arr-nms_thresh[j]))\n",
    "            nms_thresh_temp = nms_thresh_arr[i]\n",
    "\n",
    "            tp = confusion[:,i,0,0]\n",
    "            tn = confusion[:,i,1,1]\n",
    "            fn = confusion[:,i,1,0]\n",
    "            fp = confusion[:,i,0,1]\n",
    "\n",
    "            # Recall\n",
    "            rec = tp/(tp+fn)\n",
    "\n",
    "            # Number of proposals\n",
    "            no_prop = tp+fp\n",
    "            \n",
    "            if np.max(no_prop) > max_no_prop:\n",
    "                max_no_prop = np.max(no_prop)\n",
    "            \n",
    "            \n",
    "            if one_model_only == True:\n",
    "                plt.plot(no_prop,rec,marker='.',label = f'{name}, NMS thresh = {np.round(nms_thresh_temp,2)}',color=f'C{i}')\n",
    "                k=0\n",
    "                va='bottom'\n",
    "                ha='right'\n",
    "                for x, y, conf_thresh in zip(no_prop, rec, conf_thresh_arr):\n",
    "                    k+=1\n",
    "                    if k % 3 == 0:\n",
    "                        plt.text(x, y, f'{conf_thresh:.2f}', ha=ha, va=va)\n",
    "                        if va == 'bottom':\n",
    "                            va = 'top'\n",
    "                        else:\n",
    "                            va = 'bottom'\n",
    "            else:\n",
    "                plt.plot(no_prop,rec,marker='.',label = f'{name}, NMS thresh = {np.round(nms_thresh_temp,2)}')\n",
    "                \n",
    "            if nms_thresh_was_best[j] == True:\n",
    "        \n",
    "                y = np.where(best_conf_thresh[j] == conf_thresh_arr)[0][0]\n",
    "                tp = confusion[y,i,0,0]\n",
    "                fn = confusion[y,i,1,0]\n",
    "                fp = confusion[y,i,0,1]\n",
    "\n",
    "                rec = tp/(tp+fn)\n",
    "                no_prop = tp+fp\n",
    "\n",
    "                #ax.scatter(no_prop,rec,marker='*',label = 'Optimal model',color='magenta',s=100,zorder=10)\n",
    "                ax.scatter(no_prop,rec,marker='*',s=200,zorder=10)\n",
    "            \n",
    "                \n",
    "\n",
    "        if nms_thresh[j] == 'all':  \n",
    "\n",
    "            for i,nms_thresh_temp in enumerate(nms_thresh_arr):\n",
    "\n",
    "                tp = confusion[:,i,0,0]\n",
    "                tn = confusion[:,i,1,1]\n",
    "                fn = confusion[:,i,1,0]\n",
    "                fp = confusion[:,i,0,1]\n",
    "\n",
    "                # Recall\n",
    "                rec = tp/(tp+fn)\n",
    "\n",
    "                # Number of proposals\n",
    "                no_prop = tp+fp\n",
    "    \n",
    "                if np.max(no_prop) >= max_no_prop:\n",
    "                    max_no_prop = np.max(no_prop)                \n",
    "                print(max_no_prop)\n",
    "                \n",
    "                plt.plot(no_prop,rec,marker='.',label = f'NMS thresh = {np.round(nms_thresh_temp,2)}') \n",
    "              \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    rect0 = patches.Rectangle((0.0, 0.75), max_no_prop, 0.25, alpha=0.5, facecolor='darkgray')\n",
    "    \n",
    "    plt.ylim(-0.05,1.05)\n",
    "    plt.yticks([0,1/4,1/2,3/4,1])\n",
    "    # Add the rectangle patch to the axis\n",
    "    ax.add_patch(rect0)\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Number of proposals  '+ r'$TP+FP$')\n",
    "    plt.ylabel('Recall  '+ r'$\\dfrac{TP}{TP+FN}$')\n",
    "    \n",
    "    if one_model_only == True:\n",
    "        plt.title(f'Model: {name}\\nRecall vs. number of propsals')\n",
    "    else:\n",
    "        title_string = str(', '.join(names)) \n",
    "        plt.title(f'Models: {title_string}\\nRecall vs. number of propsals')\n",
    "    \n",
    "    plt.plot([0.0,max_no_prop],[0.75,0.75],color='black')\n",
    "    plt.plot([0.0,max_no_prop],[1.0,1.0],color='black')\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.show() \n",
    "\n",
    "    return\n",
    "\n",
    "def plot_recall_vs_conf_thresh(name='temp',nms_thresh='all'):\n",
    "    \n",
    "    Best_or_Last='Best'\n",
    "    \n",
    "    if isinstance(name,str):\n",
    "        one_model_only = True\n",
    "        names = [name]\n",
    "        nms_thresh = [nms_thresh]\n",
    "    \n",
    "    if isinstance(name,list):\n",
    "        one_model_only = False\n",
    "        names = name\n",
    "    \n",
    "    nms_thresh = nms_thresh.copy()\n",
    "    \n",
    "    best_conf_thresh = []\n",
    "    best_nms_thresh  = []\n",
    "    nms_thresh_was_best_1 = []\n",
    "\n",
    "    for j,name in enumerate(names):\n",
    "        conf, nms = find_conf_and_nms_thresh(name=f'{name}',Best_or_Last=f'{Best_or_Last}')\n",
    "        best_conf_thresh.append(conf)\n",
    "        best_nms_thresh.append(nms)\n",
    "    \n",
    "        if nms_thresh[j] == 'best':\n",
    "            nms_thresh[j] = best_nms_thresh[j]\n",
    "            nms_thresh_was_best_1.append(True)\n",
    "        else:\n",
    "            nms_thresh_was_best_1.append(False)\n",
    "            \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,3))\n",
    "    for j,name in enumerate(names):\n",
    "        previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "        save_path = f'{previous_model_path}/Confusion_test_{Best_or_Last}_{name}'\n",
    "\n",
    "        confusion = np.load(f'{save_path}.npy')\n",
    "\n",
    "        conf_thresh_arr = np.load(f'{previous_model_path}/conf_thresh_arr_test_{Best_or_Last}_{name}.npy')\n",
    "        nms_thresh_arr = np.load(f'{previous_model_path}/nms_thresh_arr_test_{Best_or_Last}_{name}.npy')\n",
    "\n",
    "        if nms_thresh[j] != 'all':\n",
    "            i = np.argmin(abs(nms_thresh_arr-nms_thresh[j]))\n",
    "            nms_thresh_temp = nms_thresh_arr[i]\n",
    "\n",
    "            tp = confusion[:,i,0,0]\n",
    "            tn = confusion[:,i,1,1]\n",
    "            fn = confusion[:,i,1,0]\n",
    "            fp = confusion[:,i,0,1]\n",
    "\n",
    "            # Recall\n",
    "            rec = tp/(tp+fn)            \n",
    "            \n",
    "            no_prop = tp+fp\n",
    "            \n",
    "            \n",
    "            if one_model_only == True:\n",
    "                plt.plot(conf_thresh_arr,rec,marker='.',label = f'{name}, NMS thresh = {np.round(nms_thresh_temp,2)}',color=f'C{i}')\n",
    "                k=0\n",
    "                va='bottom'\n",
    "                ha='right'\n",
    "                for x, y, conf_thresh in zip(no_prop, rec, no_prop):\n",
    "                    k+=1\n",
    "                    if k % 3 == 0:\n",
    "                        plt.text(x, y, f'{no_prop:.2f}', ha=ha, va=va)\n",
    "                        if va == 'bottom':\n",
    "                            va = 'top'\n",
    "                        else:\n",
    "                            va = 'bottom'\n",
    "            else:\n",
    "                plt.plot(conf_thresh_arr,rec,marker='.',label = f'{name}, NMS thresh = {np.round(nms_thresh_temp,2)}')\n",
    "                \n",
    "            if nms_thresh_was_best_1[j] == True:\n",
    "                y = np.where(best_conf_thresh[j] == conf_thresh_arr)[0][0]\n",
    "                tp = confusion[y,i,0,0]\n",
    "                fn = confusion[y,i,1,0]\n",
    "                fp = confusion[y,i,0,1]\n",
    "                \n",
    "                rec = tp/(tp+fn)\n",
    "                no_prop = tp+fp\n",
    "\n",
    "                #ax.scatter(no_prop,rec,marker='*',label = 'Optimal model',color='magenta',s=100,zorder=10)\n",
    "                ax.scatter(best_conf_thresh[j],rec,marker='*',s=200,zorder=10)\n",
    "            \n",
    "\n",
    "        if nms_thresh == 'all':  \n",
    "\n",
    "            for i,nms_thresh_temp in enumerate(nms_thresh_arr):\n",
    "\n",
    "                tp = confusion[:,i,0,0]\n",
    "                tn = confusion[:,i,1,1]\n",
    "                fn = confusion[:,i,1,0]\n",
    "                fp = confusion[:,i,0,1]\n",
    "\n",
    "                # Recall\n",
    "                rec = tp/(tp+fn)\n",
    "\n",
    "                # Number of proposals\n",
    "                no_prop = tp+fp\n",
    "                \n",
    "                \n",
    "                plt.plot(conf_thresh_arr,rec,marker='.',label = f'NMS thresh = {np.round(nms_thresh_temp,2)}')\n",
    "            \n",
    "        \n",
    "    \n",
    "    rect0 = patches.Rectangle((0.0, 0.75), 1.0, 0.25, alpha=0.5, facecolor='darkgray')\n",
    "    \n",
    "    plt.ylim(-0.05,1.05)\n",
    "    plt.yticks([0,1/4,1/2,3/4,1])\n",
    "    # Add the rectangle patch to the axis\n",
    "    ax.add_patch(rect0)\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Confidence threshold  '+ r'$(\\alpha)$')\n",
    "    plt.ylabel('Recall  '+ r'$\\dfrac{TP}{TP+FN}$')\n",
    "    plt.xticks(np.linspace(0.0,1.0,11))\n",
    "    \n",
    "    if one_model_only == True:\n",
    "        plt.title(f'Model: {name}\\nRecall vs. confidence threshold')\n",
    "    else:\n",
    "        title_string = str(', '.join(names)) \n",
    "        plt.title(f'Models: {title_string}\\nRecall vs. confidence threshold')\n",
    "    plt.plot([0.0,1.0],[0.75,0.75],color='black')\n",
    "    plt.plot([0.0,1.0],[1.0,1.0],color='black')\n",
    "    plt.show() \n",
    "\n",
    "    return\n",
    "\n",
    "def plot_experiment():\n",
    "    \n",
    "    names = ['hyperV2_one_hard_big','hyperV2_two_hard_big','hyperV2_three_hard_big','hyperV2_four_hard_big',\\\n",
    "             'hyperV2_five_hard_big','hyperV2_six_hard_big','hyperV2_seven_hard_big','hyperV2_eight_hard_big']\n",
    "    \n",
    "    test_loss_all = []\n",
    "    for name in names:\n",
    "        previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "        test_loss = np.load(f'{previous_model_path}/Loss_test_Best_{name}.npy')\n",
    "        test_loss_all.append(test_loss)\n",
    "    \n",
    "    \n",
    "    data = [i*(1/8)*80000 for i in range(1,9)]\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.plot(data,test_loss_all,'o-',label='HyperV2')\n",
    "    plt.title('HyperV2\\n Test loss Experiment')\n",
    "    plt.xlabel('Train data size')\n",
    "    plt.ylabel('Test loss')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_proposals_non_augmented(name='temp',Best_or_Last='Best',conf_thresh=0.6,nms_thresh=0.1,number=2,no_proposals=10):\n",
    "    \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}'    \n",
    "    \n",
    "    all_images = []\n",
    "\n",
    "    for i in range(1,5):\n",
    "        image = np.load(f'/scratch/s204219/blue_ATM/im{i}.npy')\n",
    "        image = image[:,:,:3]\n",
    "        image_tensor = torch.from_numpy(image).permute(2,0,1)\n",
    "        image_tensor = image_tensor.float()\n",
    "        all_images.append(image_tensor)\n",
    "\n",
    "\n",
    "    img_batch = torch.stack(all_images, dim=0)\n",
    "#     index = np.load(f'{previous_model_path}/Index_{train_or_val_or_test}_{name}.npy')\n",
    "    \n",
    "#     #file_root  = \"/scratch/s204219/augmentedData\"   \n",
    "#     file_root,_ = init_file_root_and_list(name=name)\n",
    "    \n",
    "#     file_list  = index[idx:idx+number*2]  \n",
    "#     # np.array([index[4],index[8]])\n",
    "    \n",
    "#     dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "    \n",
    "    RPN = init_RPN(name)\n",
    "    \n",
    "    width_scale_factor  = RPN.width_scale_factor\n",
    "    height_scale_factor = RPN.height_scale_factor\n",
    "    \n",
    "    checkpoint = torch.load(previous_model)\n",
    "    RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    n_anc_boxes_total = RPN.n_anc_boxes_total\n",
    "    \n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # e = checkpoint['epoch']\n",
    "    # loss = checkpoint['loss']\n",
    "    \n",
    "     \n",
    "    \n",
    "    # img_batch,bb_batch = dataset[:]\n",
    "    batch_size = len(img_batch)\n",
    "\n",
    "    #gt_bboxes_proj = project_bboxes(bb_batch, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "    \n",
    "    \n",
    "    proposals_final, conf_scores_final, feature_map = RPN.inference(img_batch.to(device),conf_thresh=conf_thresh,nms_thresh=nms_thresh)\n",
    "    for j in range(number):\n",
    "        proposals_final[j*2] = proposals_final[j*2][:no_proposals,:]\n",
    "        proposals_final[j*2+1] = proposals_final[j*2+1][:no_proposals,:]\n",
    "        \n",
    "        \n",
    "    \n",
    "    pos_thresh = 0.3\n",
    "    # tp,fp,fn,tn = calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='list')\n",
    "    # print('Image 1 tp:' + str(tp[i*2].detach().cpu().numpy()) + '| Image 2 tp:' + str(tp[i*2+1].detach().cpu().numpy()))    \n",
    "    \n",
    "    for i in range(number):\n",
    "                \n",
    "        if proposals_final[i*2].shape == torch.Size([0, 4]):\n",
    "            proposals_final[i*2] = torch.tensor([[0,0,0,0]],device=device)\n",
    "        if proposals_final[i*2+1].shape == torch.Size([0, 4]):\n",
    "            proposals_final[i*2+1] = torch.tensor([[0,0,0,0]],device=device)\n",
    "            \n",
    "        proposals_proj = project_bboxes(proposals_final[i*2], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu(), \\\n",
    "                       project_bboxes(proposals_final[i*2+1], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu()\n",
    "        nrows, ncols = (1, 2)\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(10, 5))\n",
    "\n",
    "        fig, axes = display_img(img_batch[i*2:i*2+2], fig, axes)\n",
    "\n",
    "        # plot proposals\n",
    "        \n",
    "        fig, _ = display_bbox(proposals_proj[0][:no_proposals,:], fig, axes[0])\n",
    "        fig, _ = display_bbox(proposals_proj[1][:no_proposals,:], fig, axes[1])\n",
    "        \n",
    "        #fig, _ = display_bbox(proposals_proj[0], fig, axes[0])\n",
    "        #fig, _ = display_bbox(proposals_proj[1], fig, axes[1])\n",
    "        \n",
    "        # add titles to the figures\n",
    "        # f'tp={tp[j]}, ' + f'fp={fp[j]}'\n",
    "        axes[0].set_title('Survey '+str(i*2+1))#, ' + f'fn={fn[i*2]}, ' + f'tn={tn[i*2]}')\n",
    "        axes[1].set_title('Survey '+str(i*2+2))#, ' + f'fn={fn[i*2+1]}, ' + f'tn={tn[i*2+1]}' )\n",
    "        \n",
    "        plt.setp(axes, xticks=[], yticks=[])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return \n",
    "\n",
    "def plot_proposals_non_preprocessed(name='temp',Best_or_Last='Best',conf_thresh=0.6,nms_thresh=0.1,number=2,no_proposals=10):\n",
    "    \n",
    "    previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "    previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}'    \n",
    "    \n",
    "    all_images = []\n",
    "\n",
    "    for i in range(1,5):\n",
    "        image = np.load(f'/scratch/s204219/blue_ATM/org_im{i}.npy')\n",
    "        image_tensor = torch.from_numpy(image).permute(2,0,1)\n",
    "        image_tensor = image_tensor.float()\n",
    "        all_images.append(image_tensor)\n",
    "\n",
    "\n",
    "    img_batch = torch.stack(all_images, dim=0)\n",
    "#     index = np.load(f'{previous_model_path}/Index_{train_or_val_or_test}_{name}.npy')\n",
    "    \n",
    "#     #file_root  = \"/scratch/s204219/augmentedData\"   \n",
    "#     file_root,_ = init_file_root_and_list(name=name)\n",
    "    \n",
    "#     file_list  = index[idx:idx+number*2]  \n",
    "#     # np.array([index[4],index[8]])\n",
    "    \n",
    "#     dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "    \n",
    "    RPN = init_RPN(name)\n",
    "    \n",
    "    width_scale_factor  = RPN.width_scale_factor\n",
    "    height_scale_factor = RPN.height_scale_factor\n",
    "    \n",
    "    checkpoint = torch.load(previous_model)\n",
    "    RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    n_anc_boxes_total = RPN.n_anc_boxes_total\n",
    "    \n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # e = checkpoint['epoch']\n",
    "    # loss = checkpoint['loss']\n",
    "    \n",
    "     \n",
    "    \n",
    "    # img_batch,bb_batch = dataset[:]\n",
    "    batch_size = len(img_batch)\n",
    "\n",
    "    #gt_bboxes_proj = project_bboxes(bb_batch, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "    \n",
    "    \n",
    "    proposals_final, conf_scores_final, feature_map = RPN.inference(img_batch.to(device),conf_thresh=conf_thresh,nms_thresh=nms_thresh)\n",
    "    for j in range(number):\n",
    "        proposals_final[j*2] = proposals_final[j*2][:no_proposals,:]\n",
    "        proposals_final[j*2+1] = proposals_final[j*2+1][:no_proposals,:]\n",
    "        \n",
    "        \n",
    "    \n",
    "    pos_thresh = 0.3\n",
    "    # tp,fp,fn,tn = calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='list')\n",
    "    # print('Image 1 tp:' + str(tp[i*2].detach().cpu().numpy()) + '| Image 2 tp:' + str(tp[i*2+1].detach().cpu().numpy()))    \n",
    "    \n",
    "    for i in range(number):\n",
    "                \n",
    "        if proposals_final[i*2].shape == torch.Size([0, 4]):\n",
    "            proposals_final[i*2] = torch.tensor([[0,0,0,0]],device=device)\n",
    "        if proposals_final[i*2+1].shape == torch.Size([0, 4]):\n",
    "            proposals_final[i*2+1] = torch.tensor([[0,0,0,0]],device=device)\n",
    "            \n",
    "        proposals_proj = project_bboxes(proposals_final[i*2], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu(), \\\n",
    "                       project_bboxes(proposals_final[i*2+1], width_scale_factor, height_scale_factor, mode='a2p').detach().cpu()\n",
    "        nrows, ncols = (1, 2)\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(10, 5))\n",
    "\n",
    "        fig, axes = display_img(img_batch[i*2:i*2+2], fig, axes)\n",
    "\n",
    "        # plot proposals\n",
    "        \n",
    "        fig, _ = display_bbox(proposals_proj[0][:no_proposals,:], fig, axes[0])\n",
    "        fig, _ = display_bbox(proposals_proj[1][:no_proposals,:], fig, axes[1])\n",
    "        \n",
    "        #fig, _ = display_bbox(proposals_proj[0], fig, axes[0])\n",
    "        #fig, _ = display_bbox(proposals_proj[1], fig, axes[1])\n",
    "        \n",
    "        # add titles to the figures\n",
    "        # f'tp={tp[j]}, ' + f'fp={fp[j]}'\n",
    "        axes[0].set_title('Survey '+str(i*2+1))#, ' + f'fn={fn[i*2]}, ' + f'tn={tn[i*2]}')\n",
    "        axes[1].set_title('Survey '+str(i*2+2))#, ' + f'fn={fn[i*2+1]}, ' + f'tn={tn[i*2+1]}' )\n",
    "        \n",
    "        plt.setp(axes, xticks=[], yticks=[])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7eaea7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# PIPELINE \n",
    "\n",
    "# For name = 'example'\n",
    "# 'example'          will use the dataset: augmentedData\n",
    "# 'example_big'      will use the dataset: augmentedData_big\n",
    "# 'example_hard'     will use the dataset: augmentedData_hard\n",
    "# 'example_hard_big' will use the dataset: augmentedData_hard_big\n",
    "\n",
    "name = 'hyperV2_one_hard_big'\n",
    "experiment = True\n",
    "dummy_pipeline = False\n",
    "cpm = False # choose_previous_model\n",
    "\n",
    "if dummy_pipeline == True:\n",
    "    conf_thresh_arr = [0.5,1]\n",
    "    nms_thresh_arr  = [0.1,0.2]\n",
    "    dataset_size = 1000\n",
    "    n_epochs = 2\n",
    "    \n",
    "if dummy_pipeline == False: \n",
    "    conf_thresh_arr = np.linspace(0.0,1.0,21)\n",
    "    nms_thresh_arr  = np.linspace(0.05,0.2,4)\n",
    "    dataset_size = 40000\n",
    "    n_epochs = 100\n",
    "\n",
    "if experiment == True:\n",
    "    dataset_size = 100000\n",
    "\n",
    "\n",
    "train_model_new(name=f'{name}',n_epochs=n_epochs,dataset_size=dataset_size,val_ratio=1/7.,test_ratio=1/7.,save=True,cpm=cpm)\n",
    "print('')\n",
    "test_model(name=f'{name}',Best_or_Last='Best')\n",
    "print('')\n",
    "\n",
    "tune_model(name=f'{name}',Best_or_Last='Best',train_or_val_or_test = 'val',\\\n",
    "           conf_thresh_arr=conf_thresh_arr,nms_thresh_arr=nms_thresh_arr, save=True)\n",
    "\n",
    "test_model_confusion(name=f'{name}',Best_or_Last='Best',conf_thresh_arr=conf_thresh_arr,nms_thresh_arr=nms_thresh_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c48df9",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot proposals\n",
    "\n",
    "name = 'baseline'\n",
    "Best_or_Last = 'Best'\n",
    "train_or_val_or_test = 'test'\n",
    "\n",
    "\n",
    "conf,nms = find_conf_and_nms_thresh(name=f'{name}', Best_or_Last=f'{Best_or_Last}')\n",
    "\n",
    "if False:\n",
    "    plot_train_val_test_proposals(name=f'{name}',Best_or_Last=f'{Best_or_Last}',\\\n",
    "                                  conf_thresh=conf,nms_thresh=nms,idx=[9,6,2],\\\n",
    "                                  number=3,no_proposals=5)\n",
    "if False:\n",
    "    plot_proposals(name=f'{name}',Best_or_Last=f'{Best_or_Last}',train_or_val_or_test=f'{train_or_val_or_test}'\\\n",
    "                   ,conf_thresh=conf,nms_thresh=nms,idx=0,number=10,no_proposals=5)\n",
    "    \n",
    "if False:\n",
    "    conf,nms = find_conf_and_nms_thresh(name='baseline', Best_or_Last='Best')\n",
    "\n",
    "    plot_proposals_non_augmented(name='baseline',Best_or_Last='Best',conf_thresh=conf,nms_thresh=nms,number=2,no_proposals=5)\n",
    "\n",
    "    plot_proposals_non_preprocessed(name='baseline',Best_or_Last='Best',conf_thresh=conf,nms_thresh=nms,number=2,no_proposals=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08f0bf5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compare models\n",
    "\n",
    "#names = ['baseline','hyperV2'] #['baseline','random','hyper'] #['baseline','random','hyper','hyperV2','resnet50hyper']\n",
    "names = ['baseline','random','hyper','hyperV2','resnet50hyper']\n",
    "\n",
    "nms_thresh = ['best']*len(names)\n",
    "nms_thresh = [0.15]*len(names)\n",
    "\n",
    "print_results(names)\n",
    "\n",
    "plot_recall_vs_number_of_propsals(name=names,nms_thresh=nms_thresh)\n",
    "\n",
    "plot_recall_vs_conf_thresh(name=names,nms_thresh=nms_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15682ea",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Print data\n",
    "file_root = \"/scratch/s204219/augmentedData\"\n",
    "file_list = np.arange(dsn+1000+0*10000,dsn+2000+0*10000) \n",
    "\n",
    "\n",
    "dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "\n",
    "for i in range(800,1000):\n",
    "    img = dataset[i][0]\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67283533",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Estimating varepsilon\n",
    "\n",
    "name = 'hyperV2_one_hard_big'\n",
    "Best_or_Last = 'Best'\n",
    "train_or_val_or_test = 'test'\n",
    "\n",
    "conf_thresh, nms_thresh = find_conf_and_nms_thresh(name='baseline', Best_or_Last='Best')\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "previous_model_path = f\"/scratch/s204219/RPN_new/{name}\"\n",
    "previous_model = f'{previous_model_path}/{Best_or_Last}_RPN_{name}'    \n",
    "\n",
    "index = np.load(f'{previous_model_path}/Index_{train_or_val_or_test}_{name}.npy')\n",
    "\n",
    "#file_root  = \"/scratch/s204219/augmentedData\"   \n",
    "file_root,_ = init_file_root_and_list(name=name)\n",
    "\n",
    "file_list  = index\n",
    "\n",
    "\n",
    "dataset = UXO_dataset(file_list=file_list, file_root=file_root)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "RPN = init_RPN(name)\n",
    "\n",
    "width_scale_factor  = RPN.width_scale_factor\n",
    "height_scale_factor = RPN.height_scale_factor\n",
    "\n",
    "checkpoint = torch.load(previous_model)\n",
    "RPN.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "n_anc_boxes_total = RPN.n_anc_boxes_total\n",
    "\n",
    "\n",
    "e = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print(e)\n",
    "\n",
    "pos_thresh = 0.3\n",
    "\n",
    "\n",
    "tp_list = np.zeros((len(dataset)))\n",
    "\n",
    "print('inference')\n",
    "idx = 0\n",
    "for img_batch, gt_bboxes_batch in dataloader:\n",
    "    gt_bboxes_proj = project_bboxes(gt_bboxes_batch, width_scale_factor, height_scale_factor, mode='p2a')\n",
    "    \n",
    "    img_batch = img_batch.to(device)\n",
    "    gt_bboxes_batch = gt_bboxes_batch.to(device)\n",
    "\n",
    "    proposals_final, conf_scores_final, feature_map = RPN.inference(img_batch,conf_thresh=conf_thresh,nms_thresh=nms_thresh)\n",
    "    \n",
    "    tp,fp,fn,tn = calc_conf_mat(gt_bboxes_proj,proposals_final,pos_thresh,n_anc_boxes_total,list_or_sum='list')\n",
    "    \n",
    "    tp_list[idx:idx+len(tp)] = tp.detach().cpu().numpy()\n",
    "    \n",
    "    idx+=len(tp)\n",
    "    \n",
    "    print(idx)\n",
    "    \n",
    "# for j in range(number):\n",
    "#     proposals_final[j*2] = proposals_final[j*2][:no_proposals,:]\n",
    "#     proposals_final[j*2+1] = proposals_final[j*2+1][:no_proposals,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print('Image 1 tp:' + str(tp[i*2].detach().cpu().numpy()) + '| Image 2 tp:' + str(tp[i*2+1].detach().cpu().numpy()))    \n",
    "\n",
    "eps = len(tp_list)/np.sum(tp_list==2)\n",
    "\n",
    "print(eps)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
